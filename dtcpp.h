/**
\file
\brief Naive implementation attempt of a classifier using a Decision Tree
for continuous data values (aka real numbers).
See doc on https://github.com/skramm/dtcpp
\author S. Kramm - 2021
\copyright GPLv3

- home: https://github.com/skramm/dtcpp
- multiclass
- Limited to binary classification (a tree node has only two childs)
- input datasets:
	- csv style
	- field separator can be defined, see Fparams
	- class field MUST be the last one
	- number of attributes set automatically
	- classes may be integer values or string values, see Fparams
- Does not handle missing values
- using boost::graph to implement the tree
*/

#ifndef DTCPP_HG
#define DTCPP_HG

//#include <iostream>
#include <fstream>
//#include <vector>
#include <numeric>
//#include <algorithm>
#include <random>
#include <iomanip>
#include <chrono>

#include <boost/graph/adjacency_list.hpp>
#include <boost/histogram.hpp>
#include <boost/bimap.hpp>
#include <boost/bimap/vector_of.hpp>

#ifdef GRAPH_SERIALIZATION
	#include <boost/archive/text_oarchive.hpp>
	#include <boost/archive/text_iarchive.hpp>
#endif

//#include "private.hpp"
#include "histac.hpp"

/// All the API and code lies here
namespace dtcpp {

// forward declaration
//class DataSet;

// % % % % % % % % % % % % % %
/// private namespace; not part of API
namespace priv {
// % % % % % % % % % % % % % %

//---------------------------------------------------------------------
/// Identifier for output file type, used in openOutputFile()
enum EN_FileType
{
	FT_CSV,FT_DAT,FT_HTML,FT_PLT,FT_DOT
};
const char*
getString( EN_FileType ft )
{
	const char* s=0;
	switch( ft )
	{
		case FT_CSV:  s = "csv";  break;
		case FT_DAT:  s = "dat";  break;
		case FT_PLT:  s = "plt";  break;
		case FT_DOT:  s = "dot";  break;
		case FT_HTML: s = "html"; break;
		default: assert(0);
	}
	return s;
}
//---------------------------------------------------------------------
/// Generic function used to open output files
auto
openOutputFile( const std::string& fn, EN_FileType ft, const std::string& data_fn=std::string() )
{
	std::ostringstream oss;
	oss << "out/" << fn << '.' << getString( ft );
	auto fname = oss.str();
	std::ofstream f(fname);
	if( !f.is_open() )
		throw std::runtime_error( "unable to open file " + fname );
	if( ft == FT_PLT )
		f << "#!/usr/bin/env gnuplot\n\n";

	if( ft == FT_HTML )
		f << "<!DOCTYPE html><head>\n<title>Datafile:"
			<< data_fn
			<< "</title>\n<link rel='stylesheet' href='out_style.css' type='text/css'>\n"
			<< "</head>\n<body>\n";

	f <<  ( ft == FT_HTML ? "<p>" : "# " )
		<< "generated by dtcpp, see "
		<<  ( ft == FT_HTML ? "<a href='https://github.com/skramm/dtcpp'>" : "" )
		<< "https://github.com/skramm/dtcpp"
		<<  ( ft == FT_HTML ? "</a><br>" : "" )
		<< '\n';
	{
		auto now = std::chrono::system_clock::now();
		auto in_time_t = std::chrono::system_clock::to_time_t(now);

		std::ostringstream ss;
		ss << std::put_time(std::localtime(&in_time_t), "%Y-%m-%d %X");
		f <<  ( ft == FT_HTML ? "" : "#" )
			<< " Generated on " << ss.str() << "\n"
			<<  ( ft == FT_HTML ? "</p>" : "" );
	}
	if( !data_fn.empty() && ft != FT_HTML )
		f << "# source data file: " << data_fn << '\n';

	f << '\n';
	return f;
}

//---------------------------------------------------------------------
/// A template to have strong types, taken from J. Boccara
/**
 * https://www.fluentcpp.com/2016/12/08/strong-types-for-strong-interfaces/

 Second type (\c Parameter) is needed so that each type is unique (see \ref ClassVal and \ref ThresholdVal types)
*/
template <typename T, typename Parameter>
class NamedType
{
public:
	NamedType() {}
	explicit NamedType(T const& value) : value_(value) {}
	explicit NamedType(T&& value) : value_(std::move(value)) {}
	T&       get()       { return value_; }
	T const& get() const { return value_; }
	bool operator == ( const NamedType& nt2 ) const
	{
		return get() == nt2.get();
	}
	bool operator != ( const NamedType& nt2 ) const
	{
		return !( *this == nt2 );
	}
	bool operator < ( const NamedType& nt2 ) const
	{
		return get() < nt2.get();
	}

	friend std::ostream& operator << ( std::ostream& f, const NamedType& nt )
	{
		f << nt.value_;
		return f;
	}
private:
	T value_;
};


// forward declaration
//template<typename U>
//class DataSet;


//-------------------------------------------------------------------
/// Remove multiple spaces AND TABS in string, allows only one, except if in first position
/**
Also replaces tabs with spaces
*/
std::string
trimSpaces( const std::string& input )
{
	assert( input.size() > 0 );
	bool HasOneAlready( false );
	bool FirstElem( true );
	std::string out;
	for( auto c: input )
	{
		if( c != ' ' && c != 9 )
		{
			out.push_back( c );
			HasOneAlready = false;
			FirstElem = false;
		}
		else {
			if( !HasOneAlready && !FirstElem )
			{
				out.push_back( ' ' ); // add a space character
				HasOneAlready = true;
			}
		}
	}
	if( out.back() == ' ' ) // if last element is a space, then remove it
		out.erase( out.end()-1 );

	return out;
}

//---------------------------------------------------------------------
/// General string tokenizer, taken from http://stackoverflow.com/a/236803/193789
/**
- see also this one: http://stackoverflow.com/a/53878/193789
*/
inline
std::vector<std::string>
splitString( const std::string &s, char delim )
{
	std::vector<std::string> velems;
	std::stringstream ss( trimSpaces(s) );
	std::string item;
	while( std::getline( ss, item, delim ) )
		velems.push_back(item);

	return velems;
}

//---------------------------------------------------------------------
/// Edge of the tree. Value is true/false of the above decision, depending on threshold
struct EdgeData
{
	bool edgeSide;
};

//---------------------------------------------------------------------
/// String to floating-point conversion utility, split on ',' or '.'.
/**
\note Needed because, with C++14, you can't convert independently of the locale !!!

\note Unfortunately, can't detect erroneous strings such as "12.34,56" because std::stoi doest not
throw if it sees a decimal separator...
*/
double
my_stod( std::string str )
{
	assert( str.size() );                // input must not be empty
	auto vc = splitString( str, ',' );
	auto vd = splitString( str, '.' );
	assert( vc.size() &&  vd.size() ); // that shouln't happen either

	if( vc.size() > 2 || vd.size() > 2 ) // can't have more than one '.' or ','
		throw std::runtime_error( "unable to convert string -" + str + "- to float" );

	double res =0.;
	if( vc.size() == 1 && vd.size() == 1 )  // no decimal separator
		try
		{
			res = 1. * std::stoi( str );  // string is an integer
		}
		catch( ... )
		{
			throw std::runtime_error( "unable to convert string -" + str + "- to float" );
		}
	else   // here, we do have a decimal separator
	{
		if( vc.size() == 2 )  // comma detected
			std::swap( vc, vd );

		auto xi = 0.;                 // value left of decimal separator
		if( vd[0].size() )            // we use stod() instead of stoi() because
			xi = std::stod( vd[0] );  // the number of digits might be to much for stoi()

		auto xf = 0.;                 // value right of decimal separator
		if( vd[1].size() )
			xf = std::stod( vd[1] );

		res = xi + xf / std::pow(10, vd[1].size() );
	}
	return res;
}

// % % % % % % % % % % % % % %
} // namespace priv
// % % % % % % % % % % % % % %

//---------------------------------------------------------------------

using ThresholdVal = priv::NamedType<float,struct ThresholdValTag>;
using ClassVal     = priv::NamedType<int,  struct ClassValTag>;

//---------------------------------------------------------------------
/// Run-time parameters for training
struct Params
{
	float minGiniCoeffForSplitting = 0.05f;
	uint  minNbPoints = 3;                   ///< minimum nb of points to create a node
	float removalCoeff = 0.01f;  ///< used to remove close attribute values when searching the best threshold. See removeDuplicates()
//	bool  verbose = true;        ///< to allow logging of some run-time details
//	int   verboseLevel = 0;      ///< verbose Level, related to \ref verbose
//	bool  doFolding = false;
//	int   nbFolds = 5;
	uint  maxTreeDepth = 12;
	bool  useSortToFindThresholds = false;
	bool  generateDotFiles = true;
	int   foldIndex = -1;
	std::ostream* outputHtml = nullptr;
};


//---------------------------------------------------------------------
/// Preliminar stuff, WIP
namespace prelim {


enum class En_DataType
{
	unknown, real_t, integer_t, string_t, bool_t
};

//---------------------------------------------------------------------
struct Attribute
{
	std::string atName;
//	uint        atIndex;
	En_DataType atType = En_DataType::unknown;
};

class DataSetDescription
{
	public:
		explicit DataSetDescription( uint nbAttribs )
			: _dataType(nbAttribs)
		{}
	private:
		std::vector<Attribute> _dataType;
};

} // namespace prelim {

//---------------------------------------------------------------------
/// A datapoint, holds a set of attributes value and a corresponding (binary) class
//template<typename T>
class DataPoint
{
//	template<typename U>
	friend class DataSet;

	private:
		std::vector<float> _attrValue;   ///< attributes
		ClassVal _class = ClassVal(-1);  ///< Class of the datapoint, -1 for undefined

#ifdef HANDLE_MISSING_VALUES
/// \name Missing Values handling
/// (enabled only if \c HANDLE_MISSING_VALUES enabled, see build options)
///@{
		std::set<uint> _missingValues;  ///< holds indexes of the attributes with missing values
	public:
		size_t nbMissingValues() const
		{
			return _missingValues.size();
		}
		bool valueIsMissing( size_t idx ) const
		{
			assert( idx < nbAttribs() );
			return ( _missingValues.find( idx ) != _missingValues.end() );

		}
		bool isMissingValue( const std::string& str ) const;
///@}
#endif

	public:
#ifdef TESTMODE
/// Constructor used in tests
		DataPoint( const std::vector<float>& vec, int c ) :
			_attrValue(vec), _class(ClassVal(c))
		{}
#endif
/// Constructor from a vector of strings (used by file reader)
		DataPoint( const std::vector<std::string>& v_string, ClassVal c )
			: DataPoint( v_string )
		{
			_class = c;
		}

/// Constructor from a vector of strings (used by file reader when no class is given)
		explicit DataPoint( const std::vector<std::string>& v_string )
		{
			assert( v_string.size() > 0 );              // at least one attribute
			for( size_t i=0; i<v_string.size(); i++ )
			try
			{
#ifdef HANDLE_MISSING_VALUES
				if( isMissingValue( v_string[i] ) )
				{
					_missingValues.insert( static_cast<uint>(i) );
					_attrValue.push_back( 0. );
				}
				else
#endif
					_attrValue.push_back( priv::my_stod( v_string[i] ) );
			}
			catch(...)
			{
				priv1::printVector( std::cerr, v_string, "string conversion error", false );
				throw std::runtime_error( "unable to convert a string value -" + v_string[i] + "- to float" );
			}
		}

/// Constructor from a vector of floats and a class value
		DataPoint( const std::vector<float>& v_val, ClassVal c ) : DataPoint( v_val )
		{
			_class = c;
		}
/// Constructor from a vector of floats and no class value
		explicit DataPoint( const std::vector<float>& v_val )
		{
			assert( v_val.size() > 0 );              // at least one attribute

			for( size_t i=0; i<v_val.size(); i++ )
				_attrValue.push_back( v_val[i] );
		}

		size_t nbAttribs() const
		{
			return _attrValue.size();
		}
		ClassVal classVal() const
		{
			assert( _class != ClassVal(-1) );
			return _class;
		}
		bool isClassLess() const
		{
			return _class == ClassVal(-1);
		}
		void setSize( size_t n ) { _attrValue.resize(n); }

		const float& attribVal( size_t idx ) const
		{
			assert( idx<_attrValue.size() );
			return _attrValue[idx];
		}
/// This (fetch by ref) is needed when tagging outliers
		float& attribVal( size_t idx )
		{
			assert( idx<_attrValue.size() );
			return _attrValue[idx];
		}

//		template<typename U>
		void setAttribVector( const std::vector<float>& vec )
		{
			assert( vec.size() == nbAttribs() );
			_attrValue = vec;
		}
		void print( std::ostream& f ) const;

		friend std::ostream& operator << ( std::ostream& f, const DataPoint& pt )
		{
			f << "Datapoint: ";
			for( const auto& v: pt._attrValue )
				f << v << '-';
			f << "C=" << pt._class.get() << ' ';
			return f;
		}
};

//---------------------------------------------------------------------
/// Parameters for reading data files
struct Fparams
{
	char sep = ' ';                   ///< Input field separator
	bool classAsString = false;       ///< Class values are given as strings
	bool dataFilesHoldsClass = true;  ///< Set to false to read files holding only attribute values (for classification task)
	bool classIsfirst = false;        ///< Default: class is last element of line, if first, then set this to true
//	uint nbBinHistograms = 15;        ///< Nb of bins for the data analysis histograms
	bool firstLineLabels = false;     ///< first line of data file holds attribute labels
};

//---------------------------------------------------------------------
/// Stats for a single attribute, see DataSet::computeStats()
template<typename T>
struct AttribStats
{
	T _minVal;
	T _maxVal;
	T _meanVal;
	T _stddevVal;
	T _medianVal;

	friend std::ostream& operator << ( std::ostream& f, const AttribStats& st )
	{
		f << "min="       << st._minVal
			<< " max="    << st._maxVal
			<< " range="  << st._maxVal - st._minVal
			<< " mean="   << st._meanVal
			<< " stddev=" << st._stddevVal
			<< " median=" << st._medianVal
			<< " ratio stddev/range=" << 100. * st._stddevVal / (st._maxVal - st._minVal)
			<< ' ';
		return f;
	}
};
//---------------------------------------------------------------------
/// Holds attribute stats, see DataSet::computeStats()
/// (mostly a wrapper on a vector, actually)
template<typename T>
struct DatasetStats
{
	private:
		std::vector<AttribStats<T>> v_stats;

	public:
/// Constructor. Argument is the number of attributes
		explicit DatasetStats( size_t nbAttribs ) : v_stats(nbAttribs)
		{}
		void add( size_t idx, const AttribStats<T>& ats )
		{
			v_stats[idx] = ats;
		}
		AttribStats<T> get( size_t idx ) const
		{
			assert( idx < v_stats.size() );
			return v_stats[idx];
		}
		friend std::ostream& operator << ( std::ostream& f, const DatasetStats<T>& st )
		{
			f << "DatasetStats: " << st.v_stats.size() << " attributes:"; // << st.nbClasses() << '\n';
			for( uint i=0; i<st.v_stats.size(); i++ )
				f << "\n -attribute " << i << ": " << st.v_stats[i];
			f << '\n';
			return f;
		}
};
//---------------------------------------------------------------------
/// Used in TrainingTree to map a class value to an index in the \ref ConfusionMatrix
using ClassIndexMap = boost::bimap<
	ClassVal,     // defaults to boost::bimaps::set_of<ClassVal>
	size_t        // defaults to boost::bimaps::set_of<size_t>
>;

using ClassStringIndexBiMap = boost::bimap<
	std::string,
	size_t
>;

using ClassCounter = std::map<ClassVal,size_t>;

//---------------------------------------------------------------------
/// Outlier Detection Method. Related to Dataset::tagOutliers()
enum class En_OD_method
{
	fixedSigma
	,ChauvenetCrit ///< \todoM See https://en.wikipedia.org/wiki/Chauvenet%27s_criterion
};
//---------------------------------------------------------------------
/// Outlier Removal Method. Related to Dataset::tagOutliers()
enum class En_OR_method
{
 	disablePoint       ///< tag the point as disabled, it will NOT be used for training
 	,replaceWithMean   ///< replace attribute value by its mean value
};

//---------------------------------------------------------------------
#ifdef HANDLE_MISSING_VALUES
/// Missing value Strategy
enum class En_MVS
{
	disablePoint,
	setToMean   ///< used mean value of attribute \todoM 20210403: not implemented yet !
};
#endif
//---------------------------------------------------------------------
/// A dataset, holds a set of \ref DataPoint
//template<typename T>
class DataSet
{
	public:
		DataSet() : _nbAttribs(0)
		{
#ifdef HANDLE_MISSING_VALUES
			DataSet::sv_MissingValueStrings.push_back("?");
#endif
//			g_params.p_dataset = this;
		}
		explicit DataSet( size_t nbAttribs ) : _nbAttribs(nbAttribs)
		{
			assert( nbAttribs );
#ifdef HANDLE_MISSING_VALUES
			DataSet::sv_MissingValueStrings.push_back("?");
#endif
//			g_params.p_dataset = this;
		}

		size_t size() const
		{ return _data.size(); }

		size_t nbAttribs() const
		{ return _nbAttribs; }

		void setNbAttribs( uint n )
		{
			assert( n>1 );
			if( size() )
				throw std::runtime_error( "cannot set size if data set not empty" );
			_nbAttribs = n;
		}

		std::vector<DataPoint>::const_iterator
		begin() const
		{
			return _data.begin();
		}
		std::vector<DataPoint>::const_iterator
		end() const
		{
			return _data.end();
		}

//		template<typename U>
		void addPoint( const DataPoint& dp )
		{
#ifdef DTCPP_ERRORS_ASSERT
			assert( dp.nbAttribs() == _nbAttribs );
#else
			if( dp.nbAttribs() != _nbAttribs )
				throw std::runtime_error(
					"nb attrib: point=" + std::to_string( dp.nbAttribs() )
					+ " dataset=" + std::to_string( _nbAttribs )
				);
#endif // DTCPP_ERRORS_ASSERT
			_data.push_back( dp );
			if( !dp.isClassLess() )
//			if( dp.classVal().get() >= 0 )
				_classCount[ dp.classVal() ]++;
			else
				_nbNoClassPoints++;

			_noChange = false;
			_cimIsUpToDate = false;
		}

//		template<typename U>
		DataPoint& getDataPoint( size_t idx )
		{
#ifdef DTCPP_ERRORS_ASSERT
			assert( idx < _data.size() );
#else
			if( idx >= _data.size() )
				throw std::runtime_error(
					"idx=" + std::to_string( idx )
					+ " dataset size=" + std::to_string( _data.size() )
				);

#endif // DTCPP_ERRORS_ASSERT

			return _data[idx];
		}
//		template<typename U>
		const DataPoint& getDataPoint( size_t idx ) const
		{
			assert( idx < _data.size() );
			return _data[idx];
		}

		bool load( std::string fname, const Fparams=Fparams() );
		void print( std::ostream& ) const;
		void print( std::ostream&, const std::vector<uint>& ) const;
		void printInfo( std::ostream&, const char* name=0 ) const;

		uint     getIndexFromClass( ClassVal ) const;
		ClassVal getClassFromIndex( uint ) const;

		void clear()
		{
			_data.clear();
			_classCount.clear();
			_classStringIndexBimap.clear();

			_nbNoClassPoints = 0u;
			_noChange = false;
			_cimIsUpToDate = false;
#ifdef HANDLE_OUTLIERS
			clearOutliers();
#endif
		}
		std::pair<DataSet,DataSet> getFolds( uint i, uint nbFolds ) const;

/// Shuffle the data (taken from https://stackoverflow.com/a/6926473/193789)
		void shuffle()
		{
			std::shuffle(std::begin(_data), std::end(_data), std::random_device() );
		}
		template<typename T>
		DatasetStats<T> computeStats( uint nbBins ) const;
#ifdef HANDLE_OUTLIERS
/// \name Outlier handling (only enabled if \c HANDLE_OUTLIERS defined, see build options)
///@{
		template<typename T>
		void tagOutliers( const DatasetStats<T>&, En_OD_method odm=En_OD_method::fixedSigma, En_OR_method orm=En_OR_method::disablePoint, float param=3.f );

/// Returns true if point has been tagged as outlier, see tagOutliers()
		bool pointIsOutlier( size_t i ) const
		{
			if( _vIsOutlier.size() )
			{
				assert( i < _vIsOutlier.size() );
				return _vIsOutlier[i];
			}
			return false;
		}
		void clearOutliers()
		{
			_vIsOutlier.clear();
			_nbOutliers = 0;
		}
		size_t nbOutliers() const
		{
			return _nbOutliers;
		}
		DataSet getSetWithoutOutliers() const;
///@}
#endif // HANDLE_OUTLIERS
		size_t nbClasses( const std::vector<uint>& ) const;

/// Returns nb of classes in the dataset, \b NOT considering the points without any class assigned
		size_t nbClasses() const
		{
			return _classCount.size();
		}

		ClassIndexMap getClassIndexMap() const
		{
			if( !_cimIsUpToDate )
			{
				size_t i = 0;                            // for each class value, fill
				for( const auto& cc: _classCount )       // the map with an incremental index
					_classIndexMap.insert( ClassIndexMap::value_type( cc.first, i++ ) );
				_cimIsUpToDate = true;
			}
			return _classIndexMap;
		}

/// Returns the number of points with class \c val (or number of non-assigned points if \c val=-1)
		size_t getClassCount( ClassVal val ) const
		{
			if( val == ClassVal(-1) )
				return _nbNoClassPoints;
			if( _classCount.count( val ) )    // we test first, because it might not be present
				return _classCount.at(val);
			return 0u;
		}

		const ClassStringIndexBiMap& getStringIndexBimap() const
		{
			return _classStringIndexBimap;
		}
		const ClassIndexMap& getIndexBimap() const
		{
			return _classIndexMap;
		}

		void generateDataHtmlPage( std::ostream&, const DatasetStats<float>& stats, int nbBins ) const;

	private:
#ifdef HANDLE_OUTLIERS
		void p_countClasses();
#endif

		template<typename T>
		void p_generateAttribPlot( char, /*const std::string& fname, */ const DatasetStats<T>&, std::ostream& ) const;
		void p_generateClassDistrib( const std::string& fname ) const;

		void p_parseTokens( std::vector<std::string>&, const Fparams&, uint&, size_t );
		template<typename HISTO>
		std::vector<std::pair<uint,uint>> p_countClassPerBin( size_t, const HISTO& ) const;

	private:
		size_t                  _nbAttribs = 0;
		std::vector<DataPoint>  _data;
		ClassStringIndexBiMap   _classStringIndexBimap;  ///< maps string labels to indexes
		ClassCounter            _classCount;             ///< Holds the number of points for each class value. Does \b NOT count classless points
		mutable ClassIndexMap   _classIndexMap;		     ///< holds correspondence between real class values (say, 1,4,7) and corresponding indexes (0,1,2)
		mutable bool            _cimIsUpToDate = false;
		uint                    _nbNoClassPoints = 0u;
		bool                    _noChange = false;
		Fparams                 _fparams;               ///< stored here, because some flags might be useful after loading
		bool                    _outlierTaggingDone = false;
#ifdef HANDLE_OUTLIERS
		size_t                  _nbOutliers = 0;        ///< to avoid recounting them when unneeded
		std::vector<bool>       _vIsOutlier;            ///< Will be allocated ONLY if tagOutliers() is called, with En_OR_method::disablePoint
#endif
	public:
		std::string             _fname;                 ///< file name (saved so it can be printed in output files)

#ifdef HANDLE_MISSING_VALUES
/** If we find any of these in a input data file, then the considered attribute for the considered datapoint will be tagged as "missing" */
		static std::vector<std::string> sv_MissingValueStrings;
		static En_MVS                   s_MissingValueStrategy;
#endif
};
//using DataSetf = DataSet<float>;
//using DataSetd = DataSet<double>;


//---------------------------------------------------------------------
#ifdef HANDLE_MISSING_VALUES
std::vector<std::string> DataSet::sv_MissingValueStrings;
En_MVS                   DataSet::s_MissingValueStrategy = En_MVS::disablePoint;

/// Used when loading the data into memory
bool
DataPoint::isMissingValue( const std::string& str ) const
{
	for( const auto& mvs: DataSet::sv_MissingValueStrings )
		if( mvs == str )
			return true;
	return false;
}
#endif
//---------------------------------------------------------------------
void
DataPoint::print( std::ostream& f ) const
{
	for( const auto& v: _attrValue )
		f << v << ' ';
	if( g_params.p_dataset )
	{
		if( isClassLess() )
			f << " -1";
		else
			f << classVal() << ' ' << g_params.p_dataset->getIndexFromClass( classVal() );
	}
	f << '\n';
}

//---------------------------------------------------------------------
uint
DataSet::getIndexFromClass( ClassVal cval ) const
{
//	COUT << "ClassVal=" << cval << '\n';
	assert( cval.get() >= 0 );
	const auto& cim = getClassIndexMap();
	return cim.left.at( cval );
}
ClassVal
DataSet::getClassFromIndex( uint idx ) const
{
//	COUT << "idx=" << idx << '\n';
	const auto& cim = getClassIndexMap();
	return cim.right.at( idx );
}
//---------------------------------------------------------------------
/// Writes in current folder a file named <code>attrib_histo_<i>.dat</code>, holding
/// the histogram of the number of points per bin for attribute \c i. Helper function for DataSet::computeStats()
/**
<br>
- Uses Boost::histogram, see https://www.boost.org/doc/libs/1_70_0/libs/histogram
*/
template<typename T>
auto
genAttribHisto(
	size_t                    atIdx,       ///< attribute index
	const std::vector<float>& vat,         ///< vector of all attribute values (size=nb of points)
	const AttribStats<T>&     atstats,
	uint                      nbBins,      ///< nb bins of the histogram
	std::string               data_fn,     ///< input datafile name
	size_t                    nbPts
)
{
	char sep = ' ';
	auto h = boost::histogram::make_histogram(
		boost::histogram::axis::regular<>(
			nbBins,
			atstats._minVal,
			atstats._maxVal
		)
	);
	std::string fname( "attrib_histo_" + std::to_string(atIdx) );
	auto f = priv::openOutputFile( fname, priv::FT_DAT, data_fn );

	std::for_each( vat.begin(), vat.end(), std::ref(h) );

	f << "# histogram for attribute " << atIdx
		<< "\n# index low_thres high_thres nb_pts percentage_of_total\n";
	for( const auto& x: boost::histogram::indexed(h) )
		f << x.index()+1 << sep << x.bin().lower() << sep << x.bin().upper() << sep << *x << sep << 100. * *x/nbPts <<  '\n';
	return h;
}
//---------------------------------------------------------------------
/// Compute statistics of an attribute.
/**
- median: https://stackoverflow.com/a/42791986/193789
- stddev: https://stackoverflow.com/a/7616783/193789

\note Argument must not be const because it will be (partially) sorted here
*/
template<typename T>
AttribStats<T>
computeAttribStats( std::vector<float>& vat )
{
	auto nbPts = vat.size();

	auto it_mm = std::minmax_element( vat.begin(), vat.end() );
	AttribStats<T> at_stat { *it_mm.first, *it_mm.second };     // sets min and max values

	auto sum = std::accumulate( vat.begin(), vat.end(), 0. );
	auto mean = sum / nbPts;
	at_stat._meanVal = mean;

	std::vector<double> diff( nbPts );
	std::transform( vat.begin(), vat.end(), diff.begin(), [mean](double x) { return x - mean; });

	auto sq_sum = std::inner_product( diff.begin(), diff.end(), diff.begin(), 0. );

	at_stat._stddevVal = std::sqrt( sq_sum / nbPts );

	if( nbPts % 2 == 0)  // if even
	{
		const auto median_it1 = vat.begin() + nbPts / 2 - 1;
		const auto median_it2 = vat.begin() + nbPts / 2;

		std::nth_element( vat.begin(), median_it1 , vat.end() );
		const auto e1 = *median_it1;

		std::nth_element( vat.begin(), median_it2 , vat.end() );
		const auto e2 = *median_it2;

		at_stat._medianVal = (e1 + e2) / 2;
	}
	else                // if odd
	{
		const auto median_it = vat.begin() + vat.size() / 2;
		std::nth_element( vat.begin(), median_it , vat.end() );
		at_stat._medianVal = *median_it;
	}
	return at_stat;
}
//---------------------------------------------------------------------
/// For each bin of the histogram \c histo: count the number of classes in the dataset, for attribute \c attrIdx
/**
\return A vector of size equal to the number of bins, holding pairs: (number of classes in bin, number of points in bin)

\todoL check if not problem here: \c histo has 2 additional bins (first and last, for values higher and lower).
Isn't that a problem ?
*/
template<typename HISTO>
std::vector<std::pair<uint,uint>>
DataSet::p_countClassPerBin( size_t attrIdx, const HISTO& histo ) const
{
	auto nbBins = histo.size();
	std::vector<std::set<ClassVal>> classSets( nbBins ); // one set of classes per bin

	for(size_t idx=0; idx<size(); idx++ )
	{
		const auto& pt = getDataPoint(idx);        // for each data point
		auto attribVal = pt.attribVal( attrIdx );  // get attribute value

		if( !pt.isClassLess() )                    // if not classless, then
#ifdef HANDLE_OUTLIERS
			if( !pointIsOutlier(idx) )             // AND not an outlier,
#endif
		{                                          // then assign it to the correct bin
			size_t i = 0;
			for (auto&& x : boost::histogram::indexed(histo) )
			{
				if( attribVal > x.bin().lower() && attribVal <= x.bin().upper() )
					classSets[i].insert( pt.classVal() );
				i++;
			}
		}
	}

	std::vector<std::pair<uint,uint>> v_ret( nbBins );
	size_t i = 0;
	for (auto&& x : boost::histogram::indexed(histo) )
	{
		v_ret[i].first  = classSets[i].size();         // number of classes in that bin
		v_ret[i].second = *x;                          // number of points in that bin
		i++;
	}

	return v_ret;
}

//---------------------------------------------------------------------
namespace priv {

/// Saves in current folder the histogram of nb of classes per bin, for attribute \c attrIdx.
/// Related: DataSet::p_countClassPerBin()
void
saveClassCountPerBin(
	size_t attrIdx,                                    ///< attribute index
	const std::vector<std::pair<uint,uint>>& v_ccpb    ///< vector of size equal to the number of bins, holding pairs: (number of classes in bin, number of points in bin)
)
{
	auto f = priv::openOutputFile( "histo_ccpb_attrib_" + std::to_string(attrIdx), priv::FT_DAT );
	assert( f.is_open() );
	f << "# attribute " << std::to_string(attrIdx)
		<< "\n# index nb_of_classes_per_bin ratio_nb_classes/nb_pts_per_bin\n";
	assert( v_ccpb.size()>3 );
/*
We start at 1 and stop before the last one, because this is build from the
Boost::histogram object, and that thing always add two additional bins, the first for
values lower than the "low" threshold, and one for values above the "high" threshold
*/
	char sep = ' ';
	for( size_t i=1; i<v_ccpb.size()-1; i++ )
	{
		f << i << sep << v_ccpb[i].first << sep;
		if( v_ccpb[i].second  )
			f << 1. * v_ccpb[i].first / v_ccpb[i].second;
		else
			f << '0';
		f << '\n';
	}
}

} // namespace priv

//---------------------------------------------------------------------
/// Outlier detection for an attribute, returns true if it is detected as so.
/// Helper function for DataSet::tagOutliers()
template<typename T>
bool
attribIsOutlier( T atval, AttribStats<T> stat, En_OD_method odm, float param )
{
	switch( odm )
	{
		case En_OD_method::fixedSigma:
			if(
				atval > stat._meanVal + param * stat._stddevVal
			||
				atval < stat._meanVal - param * stat._stddevVal
			)
				return true;
		break;

		case En_OD_method::ChauvenetCrit:
		break;

		default: assert(0);
	}
	return false; // TEMP
}
//---------------------------------------------------------------------
#ifdef HANDLE_OUTLIERS
/// Called after tagging outliers, because some classes might have vanished.
void
DataSet::p_countClasses()
{
	if( nbOutliers() == 0 && _noChange )  // then, no changes
		return;

	_nbNoClassPoints = 0;
	_classCount.clear();
	for( size_t p=0; p<size(); p++ )
	{
		const auto& pt = getDataPoint(p);

		if( !pointIsOutlier(p) )
		{
			if( pt.isClassLess() )
				_nbNoClassPoints++;
			else
				_classCount[ pt.classVal() ]++;
		}
	}
	_noChange = true;
}
//---------------------------------------------------------------------
/// Search and tag for outliers in the dataset. The exact action taken depends on \c orm
/**
- if orm=replaceWithMean, then the outlier attribute value will have its value replaced by the mean value of the attribute
- if orm=disablePoint, then the point will simply be tagged as outlier, thus not taken into account when training

Default behavior is to discard dataset points that have an attribute more than 2 sigma away from mean value.
*/
template<typename T>
void
DataSet::tagOutliers( const DatasetStats<T>& stats, En_OD_method odm, En_OR_method orm, float param )
{
	_nbOutliers = 0;
	if( orm == En_OR_method::disablePoint )
	{
		_vIsOutlier.resize( size() );
		std::fill( _vIsOutlier.begin(), _vIsOutlier.end(), false );
	}
	for( size_t p=0; p<size(); p++ )
	{
		bool ptDisabled = false;
		auto& pt = getDataPoint(p);
		for( size_t i=0; i<nbAttribs() && !ptDisabled; i++ )  // loop through all attributes
		{                                                           // but stop if point is already disabled
			auto& atval = pt.attribVal(i);
			if( attribIsOutlier( atval, stats.get(i), odm, param ) )
			{
				_nbOutliers++;
				switch( orm )
				{
					case En_OR_method::disablePoint:
						_vIsOutlier.at(p) = true;
						ptDisabled = true;
					break;
					case En_OR_method::replaceWithMean:
						atval = stats.get(i)._meanVal;
					break;
					default: assert(0);
				}
			}
		}
	}
	p_countClasses();
}
#endif
//---------------------------------------------------------------------
/// Compute statistics of the dataset, attribute by attribute, and saves histogram in data files.
/// Also generates a Gnuplot script to plot these.
/**
Done by storing for a given attribute all the values in a vector, then computing stats on that vector
*/
template<typename T>
DatasetStats<T>
DataSet::computeStats( uint nbBins ) const
{
	START;
	auto fplot = priv::openOutputFile( "plot_attrib_histo", priv::FT_PLT, _fname );
	fplot << "set terminal pngcairo size 600,600\n"
		<< "set style data histogram\n"
		<< "set style histogram cluster gap 1\n"
		<< "set style fill solid\n"
		<< "set boxwidth 1\n"
		<< "set xtic rotate by -70\n"
		<< "set grid\n\n";

	DatasetStats<T> dstats( nbAttribs() );
	for( size_t atIdx=0; atIdx<nbAttribs(); atIdx++ )
	{
		std::vector<float> vat;
		vat.reserve( size() );               // guarantees we won't have any reallocating
#ifdef HANDLE_OUTLIERS
		if( nbOutliers() == 0 )
#endif
			for( const auto& point: _data )
			{
#ifdef HANDLE_MISSING_VALUES
				if( !point.valueIsMissing( atIdx ) )
#endif
				vat.push_back( point.attribVal(atIdx) );
			}
#ifdef HANDLE_OUTLIERS
		else
#endif

			for( size_t ptIdx=0; ptIdx<size(); ptIdx++ )
			{
				const auto& point = getDataPoint(ptIdx);

#ifdef HANDLE_OUTLIERS
				if( !pointIsOutlier(ptIdx) )
#endif
#ifdef HANDLE_MISSING_VALUES
				if( !point.valueIsMissing( atIdx ) )
#endif
					vat.push_back( point.attribVal(atIdx) );
			}


		const auto& atstats = computeAttribStats<T>( vat );
		dstats.add( atIdx, atstats );

		auto histo = genAttribHisto( atIdx, vat, atstats, nbBins, _fname, size() );

		auto v_ccpb = p_countClassPerBin( atIdx, histo );
		priv::saveClassCountPerBin( atIdx, v_ccpb );

		fplot << "set output 'attrib_histo_"<< atIdx << ".png'\n"
			<< "unset label\n"
//			<< "set label 'file: " << _fname << "' at screen 0.01, screen .98 noenhanced\n"
//			<< "set label 'attribute " << atIdx << "' at screen 0.8, screen .98\n"
			<< "set multiplot layout 2,1\n"
			<< "set logscale y\n"
			<< "set title '% of pts'\n"
			<< "plot 'attrib_histo_" << atIdx << ".dat' using 5:xtic(sprintf(\"%.1e\",column(2))) noti\n"
			<< "set title 'Nb classes/nbpts of bin'\n"
			<< "set xtics format ''\n"
			<< "plot 'histo_ccpb_attrib_" << atIdx << ".dat' using 3 noti\n"
			<< "unset multiplot\n"
			<< '\n';
	}

	return dstats;
}
//---------------------------------------------------------------------
/// Returns nb of classes in the subset given by the indexes in \c vIdx
size_t
DataSet::nbClasses( const std::vector<uint>& vIdx ) const
{
	std::set<ClassVal> classSet;
	for( const auto idx: vIdx )
	{
		const auto& pt = getDataPoint( idx );
		if( !pt.isClassLess() )
			classSet.insert( pt.classVal() );
	}
	return classSet.size();
}
//---------------------------------------------------------------------
#ifdef HANDLE_OUTLIERS
/// Returns dataset without the outliers (assumes they have been tagged before!)
DataSet
DataSet::getSetWithoutOutliers() const
{
	if( nbOutliers() )
	{
		DataSet newset( nbAttribs() );
		newset._data.reserve( size() );   // to avoid reallocation
		for( size_t i=0; i<size(); i++ )
			if( !pointIsOutlier(i) )
				newset._data.push_back( getDataPoint(i) );
		return newset;
	}
	else                           // if no outliers,
		return DataSet(*this);     // then return a copy
}
#endif
//---------------------------------------------------------------------
/// Returns a pair of two subsets of the data, first is the training data, second is the test data
/**
If 100 pts and nbFolds=5, this will return 20 pts in \c ds_test and 80 pts in \c ds_train

If the \f$ nbPts/nbFolds \f$  is not an integer value, then the test set will hold \f$ nbPts/nbFolds \f$ points
and the training set will hold the rest of the points.

The \c index defines which fraction of the points are returned in the test set

If some points have been tagged as outliers, then they will \b not be included in the two returned sets.
*/
std::pair<DataSet,DataSet>
DataSet::getFolds( uint index, uint nbFolds ) const
{
 	DataSet ds_train( nbAttribs() );
 	DataSet ds_test(  nbAttribs() );

#ifdef HANDLE_OUTLIERS
	DataSet ds2 = getSetWithoutOutliers();
#else
	const DataSet& ds2 =*this;
#endif
	uint nb = ds2.size() / nbFolds;
	for( uint i=0; i<ds2.size(); i++ )
	{
		if( i / nb == index )
			ds_test.addPoint( ds2.getDataPoint(i) );
		else
			ds_train.addPoint( ds2.getDataPoint(i) );
	}

	COUT << "ds_test #=" << ds_test.size()
		<< " ds_train #=" << ds_train.size() << "\n";

	return std::make_pair( ds_train, ds_test );
}

//---------------------------------------------------------------------
// % % % % % % % % % % % % % %
namespace priv {
// % % % % % % % % % % % % % %

/// Helper function for DataSet::generateAttribPlot()
void addVerticalLine( std::ostream& f, const std::string& label, float vpos, float xpos, const std::string& color )
{
	f << "set arrow from " << xpos << ", graph 0 to " << xpos << ", graph 1 nohead lc rgb '"
		<< color << "' lw 1\n"
		<< "set label '" << label << "' at " << xpos << ", graph " << vpos << " rotate by 90 front textcolor rgb '"
		<< color << "'\n";
}
// % % % % % % % % % % % % % %
} // namespace priv
// % % % % % % % % % % % % % %

//---------------------------------------------------------------------
/// Generates two files in current folder: 1-a Gnuplot script, to plot data, and
/// 2- the whole dataset in a csv file, so that it has always the same format
/**
\note You could of course write a plotting script yourself to plot
the input data file, the code here just abstracts the input file format details,
and saves you the burden of writing such a script.<br>
Moreover, you can always tweak the generated script to fit your needs.
*/
template<typename T>
void
DataSet::p_generateAttribPlot(
	char                   ro,    ///< 'A' (No outlier removal) or 'B' (after outlier removal)
//	const std::string&     fname,  ///< File name, no extension (the 2 files will have that name, with extensions .plt and .csv)
	const DatasetStats<T>& dss,    ///< dataset stats
	std::ostream&          fhtml   ///< output html file
) const
{
	START;
	std::string fname = "class_attrib_" + ro;
	auto f1 = priv::openOutputFile( fname, priv::FT_CSV, _fname );

#ifdef HANDLE_OUTLIERS
	if( _vIsOutlier.size() )
	{
		for( size_t i=0; i<size(); i++ )
			if( !_vIsOutlier[i] )
				getDataPoint(i).print( f1 );
	}
	else
#endif
		for( const auto& pt: _data )
			pt.print( f1 );
	f1 << '\n';

	fhtml << "<table><tr>\n";
	for( size_t i=0; i<nbAttribs(); i++ )
		fhtml << "<th>Attribute " << i << "</th>\n";
	fhtml << "</tr><tr>\n";

	auto f = priv::openOutputFile( fname, priv::FT_PLT, _fname );
	f << "\nset terminal pngcairo size 600,600\n";

	if( !_fparams.classAsString )                                   // if class are not strings,
	{                                                               // they can have numeric labels
		f << "set y2label 'Class label'\nset y2tics (";             // different from 0-based indexes,
		for( size_t i=0; i<nbClasses(); i++ )                          // they are printed on the right
			f << '"' << getClassFromIndex(i) << "\" " << i << ',';
		f << ")\n";
	}
	f << "set ylabel 'Class index'"
		<< "\nset yrange [-0.5:" << nbClasses()-0.5f << ']'
		<< "\nclass=" << nbAttribs()+2
		<< "\nset datafile separator ' '"
		<< "\nset grid"
		<< "\nset ytics 0,1," << nbClasses()-1
		<< "\nset xlabel 'Attribute value'"
		<< "\n\n";

	for( size_t i=0; i<nbAttribs(); i++ )
	{
		fhtml << "<td><img src='" << fname << '_' << i << ".png'></td>\n";
		auto st = dss.get(i);
		f << "set output '" << fname << '_' << i
			<< ".png'\nunset arrow\n"
			<< "unset label\n";
//			<< "set label 'file: " << _fname << "' at screen 0.01, screen .98 noenhanced\n";
		priv::addVerticalLine( f, "mean",       0.8, st._meanVal,               "red" );
		priv::addVerticalLine( f, "mean-sigma", 0.7, st._meanVal-st._stddevVal, "blue" );
		priv::addVerticalLine( f, "mean+sigma", 0.7, st._meanVal+st._stddevVal, "blue" );
		priv::addVerticalLine( f, "median",     0.6, st._medianVal,             "green" );
		f << "set title 'Class vs. attribute " << i
			<< "'\nplot '" << fname << ".csv' using " << i+1 << ":class notitle\n\n";
	}
	fhtml << "</tr>\n</table>\n";
}

//---------------------------------------------------------------------
/// Helper member function for DataSet::load()
void
DataSet::p_parseTokens(
	std::vector<std::string>&   v_tok,             ///< string tokens read on line
	const Fparams&              params,            ///< parameters
	uint&                       classIndexCounter, ///< the next index value for classes as strings
	size_t                      nb_lines           ///< in case of error
)
{
	if( !params.dataFilesHoldsClass )
		_data.push_back( DataPoint( v_tok ) );
	else
	{
		int classIndex = -1;
		auto cla = v_tok.back();
		if( params.classIsfirst )
			cla = v_tok.front();

		if( !params.classAsString )
		{
			try
			{
				classIndex = std::stoi( cla );
			}
			catch( ... )
			{
				throw std::runtime_error( "Unable to convert string '" + cla + "' on line " + std::to_string(nb_lines) + " to an integer value" );
			}
		}
		else
		{
			auto it = _classStringIndexBimap.left.find( cla );
			if( it == _classStringIndexBimap.left.end() )  // if not registered, then
			{
				classIndex = classIndexCounter;
				_classStringIndexBimap.insert( ClassStringIndexBiMap::value_type( cla, classIndexCounter) );             // new class, add it
				classIndexCounter++;
			}
			else
				classIndex = _classStringIndexBimap.left.at( cla );
		}
		if( classIndex < 0 )
			_nbNoClassPoints++;

		else
			_classCount[ ClassVal(classIndex) ]++;

		if( params.classIsfirst )
			std::rotate( v_tok.begin(), v_tok.begin()+1, v_tok.end() );
		v_tok.erase( v_tok.end()-1 );   // remove last element (class)
		_data.push_back( DataPoint( v_tok, ClassVal(classIndex) ) );
	}
}
//---------------------------------------------------------------------
/// Load data file into memory, returns false on failure
//template<typename T>
bool
DataSet::load( std::string fname, const Fparams params )
{
	std::ifstream f( fname );
	if( !f.is_open() )
	{
		std::cerr << "Unable to open file " << fname << "\n";
		return false;
	}
	_fparams = params;
	_fname   = fname;
	clear();

	uint classIndexCounter = 0;

	size_t nb_lines     = 0;
	size_t nb_empty     = 0;
	size_t nb_comment   = 0;
	do
	{
		std::string temp;
		std::getline( f, temp );
		nb_lines++;

		if( !params.firstLineLabels || nb_lines != 1 )
		{
			if( temp.empty() )          // if empty
				nb_empty++;
			else                        // if NOT empty
			{
				if( temp.at(0) == '#' )  // if comment
					nb_comment++;
				else                     // if NOT comment
				{
					auto v_tok = priv::splitString( temp, params.sep );
					if( v_tok.size() < 2 )
					{
						std::cerr << "-Error: only one value on line " << nb_lines
							<< "\n-Line=" << temp << " \n-length=" << temp.size() << '\n';
						return false;
					}

					if( size() == 0 )                    // if this is the first datapoint, then set the nb of attributes
						setNbAttribs( params.dataFilesHoldsClass ? v_tok.size()-1 : v_tok.size() );

					p_parseTokens( v_tok, params, classIndexCounter, nb_lines );
				}
			}
		}
	}
	while( !f.eof() );

	_cimIsUpToDate = false;
	_noChange      = false;
	g_params.p_dataset = this;
#if 1
	std::cout << " - Read " << size() << " points in file " << fname;
	std::cout << "\n - file info:"
		<< "\n  - nb lines=" << nb_lines
		<< "\n  - nb empty=" << nb_empty
		<< "\n  - nb comment=" << nb_comment
		<< "\n  - nb classes=" << nbClasses()
		<< '\n';
#endif
	return true;
}
//---------------------------------------------------------------------
/// Generates in Html page the code to show the produced plots
void
DataSet::generateDataHtmlPage( std::ostream& fhtml, const DatasetStats<float>& stats, int nbBins ) const
{
	fhtml << "<h2>A - Dataset characteristics</h2>\n<ul>\n"
		<< "<li>name: " << _fname
		<< "</li>\n<li># points=" << size()
		<< "</li>\n<li># attributes="       << nbAttribs()
		<< "</li>\n<li># classes="          << nbClasses()
		<< "</li>\n<li># classless points=" << _nbNoClassPoints
		<< "</li>\n<li># outliers removed:" << (_outlierTaggingDone?"YES":"NO")
		<< "</li>\n</ul>\n";

	if( _fparams.classAsString )
	{
		fhtml << "<h4>Class strings => indexes:</h4>\n<ul>\n";
		for( const auto& psi: _classStringIndexBimap.left )
			fhtml << "<li>\"" << psi.first << "\" : " << psi.second << "</li>\n";
		fhtml << "</ul>\n";
	}

	fhtml << "<h4>Classes frequency:</h4>\n<ol>\n";
	size_t sum = 0;
	size_t c = 0;
	for( const auto& cval: _classCount )
	{
		fhtml << "<li> : " <<  cval.first << " - "
			<< cval.second
			<< " (" << std::setw(4) << 100. * cval.second/size()
			<< " %)</li>\n";
		sum += cval.second;
	}
	fhtml << "</ol>\n => " << sum << " points holding a class value\n\n";

	char otd = _outlierTaggingDone?'B':'A';
	fhtml << "<h3>A1 - Class distribution</h3>\n"
		<< "<img src='class_distrib_" << otd << ".png'>\n";
	p_generateClassDistrib( "class_distrib_" + otd );


	fhtml << "<h3>A2 - Class vs. attribute values</h3>\n";
	p_generateAttribPlot( otd, stats, fhtml );

// TODO
//	generateClassHistoPerTVal( nodeId, atIdx, v_thresVal, data, v_dpidx );

	fhtml << "<h3>A3 - Histogram of data related to attribute value</h3>\n<table><tr>\n";
	for( uint i=0; i<nbAttribs(); i++ )
		fhtml << "<th>Attribute " << i << "</th>\n";
	fhtml << "</tr><tr>\n";
	for( uint i=0; i<nbAttribs(); i++ )
		fhtml << "<td>\n <img src='attrib_histo_" << i << ".png'></td>\n";
	fhtml << "</tr></table>\n";
}

//---------------------------------------------------------------------
/// Generates both data files and Gnuplot script of the class distribution of the dataset
void
DataSet::p_generateClassDistrib( const std::string& fname ) const
{
	START;

	auto fhisto = priv::openOutputFile( fname, priv::FT_DAT, _fname );

	fhisto << "# data class histogram file for input file '" <<  fname
		<< "'\n# class_index occurence_count percentage\n"
		<< "NC " << getClassCount( ClassVal(-1) ) << ' '
		<< 100. * getClassCount( ClassVal(-1) ) / size() << '\n';

	for( const auto& cval: _classCount )
		fhisto << cval.first << ' '
			<< cval.second << ' ' << 100. * cval.second/size()
			<< '\n';

	auto fplot = priv::openOutputFile( fname, priv::FT_PLT, _fname );
	fplot << "set terminal pngcairo size 600,600\n"
		<< "set output '" << fname << ".png'\n"
		<< "set title 'Class distribution'\n"
//		<< "set label 'file: " << _fname << "' at screen 0.01, screen .98 noenhanced\n"
		<< "set ylabel '% of total points'\n"
		<< "set xlabel 'Class'\n"
		<< "set style data histogram\n"
		<< "set style histogram cluster gap 1\n"
		<< "set style fill solid\n"
		<< "set boxwidth 1\n"
		<< "plot '" << fname << ".dat' using 3:xtic(1) notitle\n";
}

//---------------------------------------------------------------------
void
DataSet::printInfo( std::ostream& f, const char* name ) const
{
	f << "------------------------\nDataset: ";
	if( name )
		f << name;
	f << "\n # points="             << size()
		<< "\n # attributes="       << nbAttribs()
		<< "\n # classes="          << nbClasses()
		<< "\n # classless points=" << _nbNoClassPoints
#ifdef HANDLE_OUTLIERS
		<< "\n # outliers=" << _nbOutliers
#endif
		<< '\n';

	if( _fparams.classAsString )
	{
		f << "- Class strings => indexes:\n";
		for( const auto& psi: _classStringIndexBimap.left )
			f << " -\"" << psi.first << "\": " << psi.second << '\n';
	}

	f << "- Classes frequency:\n";
	size_t sum = 0;
	size_t c = 0;
	f << " # : label - Nb  %\n"; //-----------------------------\n";

	for( const auto& cval: _classCount )
	{
		f << ++c << " : " <<  cval.first << " - "
			<< cval.second
			<< " (" << std::setw(4) << 100. * cval.second/size()
			<< " %)\n";
		sum += cval.second;
	}
	f << " => " << sum << " points holding a class value\n\n";
}
//---------------------------------------------------------------------
//template<typename T>
void
DataSet::print( std::ostream& f ) const
{
	f << "# -------------------------------------------\n";
	f << "# Dataset, nb pts=" << size() << " nb attributes=" << nbAttribs() << "\n";
	for( size_t i=0; i<nbAttribs(); i++ )
		f << i << "; ";
	f << " class\n";

	for( const auto& pt: _data )
		f << pt;
	f << "# -------------------------------------------\n";
}
//---------------------------------------------------------------------
//template<typename T>
void
DataSet::print( std::ostream& f, const std::vector<uint>& vIdx ) const
{
	f << "# -------------------------------------------\n";
	f << "# Dataset, total nb pts=" << size()
		<< " requested=" << vIdx.size()
		<< " nb attributes=" << nbAttribs() << "\n";
	for( size_t i=0; i<nbAttribs(); i++ )
		f << i << "; ";
	f << " class\n";
	for( const auto& id: vIdx )
	{
		const auto& pt = getDataPoint( id );
		f << id << " ";
		for( const auto& val: pt._attrValue )
			f << val << ";";

		f << pt.classVal() << "\n";
	}
	f << "# -------------------------------------------\n";
}

//---------------------------------------------------------------------
/// Holds the node type, see NodeT
enum NodeType : char
{
	 NT_undef = 0
	 ,NT_Root                 ///< Root node
	 ,NT_Decision             ///< Decision Node
	 ,NT_Final_MD             ///< Leave, cause: reached Max Depth
	 ,NT_Final_SC             ///< Leave, single class in dataset considered points
	 ,NT_Final_GI_Small       ///< Leave, cause: Information Gain is small enough
	 ,NT_Final_SplitTooSmall  ///< Leave, cause: unable to split, nb of points would be too small
	 ,NT_Merged               ///< Leave than has been merge with another at pruning step
};

inline
std::string
getString( NodeType nt )
{
	const char* s = nullptr;
	switch( nt )
	{
		case NT_undef:    s="UNDEF";    break;
		case NT_Root:     s="Root";     break;
		case NT_Decision: s="Decision"; break;
		case NT_Final_SC:            s="SC";  break;
		case NT_Final_MD:            s="MD";  break;
		case NT_Final_GI_Small:      s="MGI"; break;
		case NT_Final_SplitTooSmall: s="STS"; break;
		case NT_Merged:              s="MP";  break;
		default: assert(0);
	}
	return std::string(s);
}
//---------------------------------------------------------------------
/// A node of the training tree, this is used in the graph (see \ref GraphT)
struct NodeT
{
	private:
		static uint s_Counter;           ///< Node counter, incremented at each node creation, reset with resetNodeId()
	public:
		uint     _nodeId = 0;            ///< Id of the node. Needed to print the dot file. \todoL could be removed if graph switches to \c VecS
		NodeType _type = NT_undef;       ///< Type of the node (Root, leaf, or decision)
		ClassVal _nClass = ClassVal(-1); ///< Class, relevant only for terminal nodes (leaves of the tree)
		size_t   _attrIndex = 0;         ///< Attribute Index that this nodes classifies (only for decision nodes)
		float    _threshold = 0.f;       ///< Threshold on the attribute value (only for decision nodes)
		uint     _depth = 0;             ///< Depth of the node in the tree
		float    _giniImpurity = 0.f;
		float    _nAmbig = -1.f;
		std::vector<uint> v_Idx;         ///< Data point indexes

	friend std::ostream& operator << ( std::ostream& f, const NodeT& n )
	{
		f << "C=" << n._nClass
			<< "\ntype=" << getString(n._type)
			<< "\nattr=" << n._attrIndex
			<< "\nthres=" << n._threshold
			<< "\ndepth=" << n._depth
			<< "\n#v=" << n.v_Idx.size()
			;
		return f;
	}

	bool isLeave() const
	{
		assert( _type != NT_undef );
		if( _type == NT_Root )
			return false;
		if( _type == NT_Decision )
			return false;
		return true;
	}

/// Reset of node counter \ref s_Counter
	static void resetNodeId()
	{
		s_Counter = 0;
	}
	NodeT() { _nodeId = s_Counter++; }
	NodeT( const NodeT& ) = delete;
	NodeT& operator= ( const NodeT& ) = delete;
};

 /// Instanciation of static counter
 uint NodeT::s_Counter = 0;

//---------------------------------------------------------------------
/// Used for training
/**
\note IMPORTANT: we use list because when splitting the vector of indexes of points of a node,
we use the current node's vector as a reference (to avoid copying the whole vector).
BUT: if we where using \c vectS, adding new nodes may invalidate the current vertex descriptor.
Thus, we use \c listS
\todoL: actually, maybe we need to use ListS only for ONE of the two containers. Check BGL doc
to see what these two template parameters are used for.

\note 2021-03-01: changed from \c directedS to \c bidirectionalS: required to be able to get in_edges (see TraingTree::pruning())
*/
using GraphT = boost::adjacency_list<
		boost::listS,  // boost::vecS,
		boost::listS,
		boost::bidirectionalS, //boost::directedS,
		NodeT,
		priv::EdgeData
	>;

using vertexT_t = boost::graph_traits<GraphT>::vertex_descriptor;
using edge_t = boost::graph_traits<GraphT>::edge_descriptor;

//---------------------------------------------------------------------
// forward declaration, needed for the friend declaration below
class ConfusionMatrix;

// % % % % % % % % % % % % % %
namespace priv {
// % % % % % % % % % % % % % %

/// Private class, used to hold the counters extracted from the ConfusionMatrix,
/// see ConfusionMatrix::p_score()
class CM_Counters
{
	friend class dtcpp::ConfusionMatrix;

	CM_Counters( double TP, double FP, double TN, double FN )
		: tp(TP),fp(FP),tn(TN), fn(FN)
	{
		assert( tp + fp + tn + fn > 0 );
	}
	double tp,fp,tn,fn;
};
// % % % % % % % % % % % % % %
} // namespace priv
// % % % % % % % % % % % % % %

//---------------------------------------------------------------------
/// Performance score of classification, see ConfusionMatrix for definitions
enum class PerfScore
{
	TPR=0    ///< True Positive Rate (recall)
	,TNR     ///< True Negative Rate
	,PPV     ///< Positive Predictive Value  (precision)
	,ACC     ///< Accuracy
	,BACC    ///< Balanced Accuracy
	,F1      ///< F1-score, see https://en.wikipedia.org/wiki/F-score

	,SCORE_END  ///< only used to iterate
};

//---------------------------------------------------------------------
/// Multiclass performance score, see ConfusionMatrix::getScore_MC()
enum class PerfScore_MC
{
	PRECIS_M      ///< Macro Precision
	,RECALL_M     ///< Macro Recall
	,PREC_REC_m   ///< Micro precision-recall (is the same)
	,FSCORE_M     ///< FScore

	,SCORE_END    ///< only used to iterate
};
//---------------------------------------------------------------------
std::string
getString( PerfScore n )
{
	const char* s = nullptr;
	switch( n )
	{
		case PerfScore::TPR:  s="TPR (recall)";  break;
		case PerfScore::TNR:  s="TNR";  break;
		case PerfScore::PPV:  s="PPV (prec)";  break;
		case PerfScore::ACC:  s="ACC";  break;
		case PerfScore::BACC: s="BACC"; break;
		case PerfScore::F1:   s="F1";   break;
		default: assert(0);
	}
	return std::string(s);
}
//---------------------------------------------------------------------
std::string
getString( PerfScore_MC n )
{
	const char* s = nullptr;
	switch( n )
	{
		case PerfScore_MC::RECALL_M: s="(macro) Recall";  break;
		case PerfScore_MC::PRECIS_M: s="(macro) Precision";  break;
		case PerfScore_MC::PREC_REC_m: s="(micro) Precision/Recall";  break;
		case PerfScore_MC::FSCORE_M: s="(macro) Fscore";  break;
		default: assert(0);
	}
	return std::string(s);
}

//---------------------------------------------------------------------
#if 0
/// Container for the performance scores
struct Scores
{
	std::array<double, static_cast<int>(PerfScore::SCORE_END)> _sScoreValues;
};
#endif
//---------------------------------------------------------------------
/// Confusion Matrix, handles both 2 class and multiclass problems, but usage will be different.
/**

Instanciated in TrainingTree::classify()

- Layout:
 - columns: true class
 - lignes: predicted (classified) class

- To get the associated performance scores, use getScore() (2 versions).

- Definitions of performance scores:
 - For 2- class problems, follows definitions from https://en.wikipedia.org/wiki/Confusion_matrix
 - For multiclass, see definitions here: https://stats.stackexchange.com/a/338240/23990
and here: https://towardsdatascience.com/multi-class-classification-extracting-performance-metrics-from-the-confusion-matrix-b379b427a872

Usage:

For 2-class problem, you get (for example) the "True Positive Rate" metric like this:
\code
	auto score = cmat.getScore( TPR );
\endcode

For multiclass situations, you need to add for what class you are requesting this.
\code
	auto score = cmat.getScore( TPR, ClassValue );
\endcode

*/
struct ConfusionMatrix
{
	friend std::ostream& operator << ( std::ostream&, const ConfusionMatrix& );

	explicit ConfusionMatrix( ClassIndexMap cim )
		: _cmClassIndexMap(cim)
	{
		auto nbClass = cim.size();
		assert( nbClass>1 );
		_mat.resize( nbClass );
		for( auto& li: _mat )
		{
			li.resize( nbClass );
			std::fill( li.begin(), li.end(), 0u );
		}
	}

#ifdef TESTMODE
/// Constructor only for testing
	explicit ConfusionMatrix( size_t nbClasses )
	{
		assert( nbClasses>1 );
		_mat.resize( nbClasses );
		uint i = 0;
		for( auto& li: _mat )
		{
			li.resize( nbClasses );
			std::fill( li.begin(), li.end(), 0u );
			_cmClassIndexMap.insert( ClassIndexMap::value_type(  ClassVal(i), i ) );
			i++;
		}
	}

	explicit ConfusionMatrix( const std::vector<std::vector<uint>>& m ) : _mat(m)
	{}
#endif //  TESTMODE

	void clear()
	{
		for( auto& li: _mat )
			std::fill( li.begin(), li.end(), 0u );
	}
	size_t nbClasses() const
	{
        return _mat.size();
	}

    double getScore( PerfScore, ClassVal ) const;
    double getScore( PerfScore ) const;
	double getScore_MC( PerfScore_MC scoreId ) const;

	template<typename T>
	double getScoreT( T ) const;

/// Returns total number of values in matrix
	size_t nbValues() const
	{
		size_t sum = 0u;
		for( const auto& li: _mat )
			sum += std::accumulate( li.begin(), li.end(), 0u );
		return sum;
	}

/// Returns number of \b predicted values for class \c cval
	size_t nbValues( ClassVal cval ) const
	{
		assert( cval.get() >= 0 );
		auto li  = static_cast<size_t>( cval.get() );
		assert( li < _mat.size() );
		return std::accumulate( _mat[li].begin(), _mat[li].end(), 0u );
	}

	void add( ClassVal trueVal, ClassVal predictedVal )
	{
		assert( trueVal.get() >= 0 );
		assert( predictedVal.get() >=0 );
		assert( _cmClassIndexMap.size() );

		auto col = _cmClassIndexMap.left.at( trueVal );
		auto li  = _cmClassIndexMap.left.at( predictedVal );

		assert( li < _mat.size() && col < _mat.size() );
		_mat[li][col]++;
	}

	void printAllScores( std::ostream&, const char* msg=0 ) const;

#ifdef TESTMODE
	void setVal( size_t li, size_t col, uint v )
	{
		_mat[li][col] = v;
	}
#endif //  TESTMODE

	private:
		double p_score( PerfScore scoreId, priv::CM_Counters ) const;

	private:
		std::vector<std::vector<uint>> _mat;
		ClassIndexMap                  _cmClassIndexMap;
};

//---------------------------------------------------------------------
// % % % % % % % % % % % % % %
namespace priv {
// % % % % % % % % % % % % % %
void printLine( std::ostream& f, uint w, uint n )
{
	f << '|'
		<< std::string( (w+1)*n+1, '-' )
		<< '|';
}
// % % % % % % % % % % % % % %
} // namespace priv
// % % % % % % % % % % % % % %
//---------------------------------------------------------------------
/// Streaming of \ref ConfusionMatrix
std::ostream&
operator << ( std::ostream& f, const ConfusionMatrix& cm )
{
	auto nbVal = cm.nbValues();
	size_t w = std::max( (size_t)3, (size_t)std::to_string( nbVal ).size() );
	auto nbCl = cm._mat.size();
	f << std::setfill(' ');
	f << "ConfusionMatrix:\nPredicted \\ True class =>\n ||   ";

	for( const auto & pci: cm._cmClassIndexMap.left )
		f << std::setw(w) << pci.first << " ";

	f << "   class\n \\/ ";
	priv::printLine( f, w, nbCl );
	f << "   # | rate\n";

	std::vector<size_t> sumCol( nbCl, 0u );
	size_t li = 0;
	for( const auto & pci: cm._cmClassIndexMap.left )
	{
		f << std::setw(3) << pci.first << " | ";

		for( size_t col=0; col<nbCl; col++ )
		{
			f << std::setw(w) << cm._mat[li][col] << ' ';
			sumCol[col] += cm._mat[li][col];
		}
		f << "| "
			<< std::setw(w) << cm.nbValues( ClassVal(li) ) << "  "
			<< std::setprecision(3)
			<< 100.0 * cm.nbValues( ClassVal(li) ) / nbVal
			<< "%\n";
		li++;
	}
	f << "    ";
	priv::printLine( f, w, nbCl );
	f << "\nsum | ";
	for( size_t col=0; col<nbCl; col++ )
		f << std::setw(w) << sumCol[col] << ' ';
	f <<  "| " << std::setw(w)
		<< std::accumulate( sumCol.begin(), sumCol.end(), 0u )
		<< '\n';
	return f;
}

//---------------------------------------------------------------------
/// Private, compute scores for both 2-class and multi-class confusion matrices
/// (for a given class).
double
ConfusionMatrix::p_score( PerfScore scoreId, priv::CM_Counters cmc ) const
{
	auto TPR = cmc.tp / ( cmc.tp + cmc.fn );
	auto TNR = cmc.tn / ( cmc.tn + cmc.fp );
	double scoreVal = 0.;
	switch( scoreId )
	{
		case PerfScore::TPR:  scoreVal =  TPR; break;
		case PerfScore::TNR:  scoreVal =  TNR; break;
		case PerfScore::PPV:  scoreVal =  cmc.tp / ( cmc.tp + cmc.fp ); break;
		case PerfScore::ACC:  scoreVal = (cmc.tp + cmc.tn)/nbValues();  break;
		case PerfScore::BACC: scoreVal = (TPR + TNR ) / 2.; break;
		case PerfScore::F1:   scoreVal = 2.* cmc.tp / ( 2.* cmc.tp + cmc.fp + cmc.fn ); break;
		default: assert(0);
	}
	return scoreVal;
}
//---------------------------------------------------------------------
/// Computes performance scores. Used for 2-class situations
double
ConfusionMatrix::getScore( PerfScore scoreId ) const
{
	assert( nbValues() > 1 );
	assert( nbClasses() == 2 );

	const auto& TP = _mat[0][0];
	const auto& FP = _mat[0][1];
	const auto& FN = _mat[1][0];
	const auto& TN = _mat[1][1];

	return p_score( scoreId, priv::CM_Counters(TP,FP,TN,FN) );
}
//---------------------------------------------------------------------
/// Computes and return a performance score. Used for multi-class situations
/**
- TP: True Positive
- FP: False Positive
- FN: False Negative
- TN: True Negative
*/
double
ConfusionMatrix::getScore( PerfScore scoreId, ClassVal cval ) const
{
	assert( nbValues() > 2 );
	assert( nbClasses() > 2 );

	assert( cval.get() >= 0 );
	size_t c = static_cast<size_t>( cval.get() );
	assert( c < nbClasses() );

	const auto& TP = _mat[c][c];

	const auto FP = std::accumulate( std::begin(_mat[c]), std::end(_mat[c]), 0. ) - TP;

	auto FN = 0u;
	for( size_t li=0; li<_mat.size(); li++ )
		if( li != c )
			FN += _mat[li][c];

	const auto TN = nbValues() - TP - FN - FP;

	return p_score( scoreId, priv::CM_Counters(TP,FP,TN,FN) );
}
//---------------------------------------------------------------------
/// Computes and return a single performance score (identified by \c scoreId) for a multiclass task (MC).
/**
- Reference:
Sokolova, M., & Lapalme, G. (2009), "A systematic analysis of performance measures for classification tasks".
Information Processing and Management, 45, p. 427-437

- for the Fscore, we use beta=1 (see https://en.wikipedia.org/wiki/F-score#Definition)

\image html Sokolova_2009_table.png
*/
double
ConfusionMatrix::getScore_MC( PerfScore_MC scoreId ) const
{
	assert( nbValues() > 2 );
	assert( nbClasses() > 2 );

	auto val = 0.;
	switch( scoreId )
	{
		case PerfScore_MC::PRECIS_M:                   // macro precision
			for( size_t i=0; i<nbClasses(); i++ )
			{
				auto sum_li = std::accumulate( std::begin(_mat[i]), std::end(_mat[i]), 0. );
				if( sum_li > 0 )
					val += _mat[i][i] / std::accumulate( std::begin(_mat[i]), std::end(_mat[i]), 0. );
			}
			val /= nbClasses();
			break;

		case PerfScore_MC::RECALL_M:                  // macro recall
			for( size_t i=0; i<nbClasses(); i++ )
			{
				auto sum_col = 0.;
				for( size_t li=0; li<nbClasses(); li++ )
					sum_col += _mat[li][i];
				if( sum_col > 0 )
					val += _mat[i][i] / sum_col;
			}
			val /= nbClasses();
		break;

		case PerfScore_MC::PREC_REC_m:                  // micro precision-recall
			for( size_t i=0; i<nbClasses(); i++ )
				val += _mat[i][i];
			val /= nbValues();
		break;

		case PerfScore_MC::FSCORE_M:               // macro F-Score
		{
			auto p = getScore_MC( PerfScore_MC::PRECIS_M );
			auto r = getScore_MC( PerfScore_MC::RECALL_M );
			val = 2. * p * r / ( p + r );
		}
		break;

		default : assert(0);
	}
	return val;
}

//---------------------------------------------------------------------
template<typename T>
double
ConfusionMatrix::getScoreT( T pc ) const
{
	static_assert( std::is_same<T,PerfScore_MC>::value, "invalid type" );
	return getScore_MC( pc );
}
template<>
double
ConfusionMatrix::getScoreT<PerfScore>( PerfScore pc ) const
{
	return getScore( pc );
}

//---------------------------------------------------------------------
/// Prints all the performance scores
void
ConfusionMatrix::printAllScores( std::ostream& f, const char* msg ) const
{
	f << "Performance scores";
	if( msg )
		f << " - " << msg;
	f << ":\n";
	if( nbClasses() > 2 )
	{
		for( auto i=0; i<static_cast<int>(PerfScore_MC::SCORE_END); i++ )
		{
			auto eni = static_cast<PerfScore_MC>(i);
			f << "   - " << getString( eni ) << " = " << getScoreT<PerfScore_MC>( eni ) << '\n';
		}
	}
	else
	{
		for( auto i=0; i<static_cast<int>(PerfScore::SCORE_END); i++ )
		{
			auto eni = static_cast<PerfScore>(i);
			f << " - " << getString( eni ) << " = " << getScoreT<PerfScore>( eni ) << '\n';
		}
	}
}
//---------------------------------------------------------------------
/// This is returned by TrainingTree::train(), holds some information
/// on training process
struct TrainingInfo
{
	size_t nbRemovals = 0;
	bool   trainingSuccess = false;

	friend std::ostream& operator << ( std::ostream& f, const TrainingInfo& ti )
	{
		f << "TrainingInfo:"
			<< "\n - nbRemovals=" << ti.nbRemovals
			<< '\n';
		return f;
	}
};
//---------------------------------------------------------------------
/// This one holds edges that each have a vector holding the index of datapoints.
/// This is memory costly, but useless for classifying, so once it is trained, we could use another tree type
/**
Two constructors available, depending on the situation
- the first one requires only the number of classes. However, the assumes the classes will be identified
by their value, i.e. if we have 3 classes, then the \b MUST have the values 0, 1, 2.
If not, then this will cause an error, because access to the \ref ConfusionMatrix will be made using the class
values as indexes. And if the class values are "3", "4", "5", this will trigger an error.
- the second constructor need a \ref ClassIndexMap object, that will enable using the true values of the class to
access the Confusion Matrix. It can be generated from a source dataset with:
\code
	auto classIndexMap = dataset.getClassIndexMap();
\endcode
*/
//template<typename T>
class TrainingTree
{
	friend void splitNode( vertexT_t, GraphT&, DataSet&, const Params& );

	private:
#ifdef TESTMODE
	public:
#endif
		GraphT        _graph;
		vertexT_t     _initialVertex;
		uint          _maxDepth = 1;  ///< defined by training
		ClassIndexMap _tClassIndexMap;  ///< maps class values to index values
		std::string   _dataFileName = "(NO DATA)"; ///< used to print input file name on plot

	public:
//#ifdef TESTMODE
/// Constructor 1, only for testing
		TrainingTree()
		{
			clear();
		}
//#endif
/// Constructor 2, to be used if class values can not be used as indexes.
		explicit TrainingTree( const ClassIndexMap& cim )
			: _tClassIndexMap( cim )
		{
			clear();
		}
		TrainingTree( const TrainingTree& ) = delete;

		void assignCIM( const ClassIndexMap& cim )
		{
			_tClassIndexMap = cim;
		}
/// This does clear the tree and creates the initial (root) node
		void clear()
		{
			_graph.clear();
			NodeT::resetNodeId();
			_initialVertex = boost::add_vertex(_graph);  // create initial vertex
			_graph[_initialVertex]._type = NT_Root;
		}
#ifdef GRAPH_SERIALIZATION
		void saveToFile(   const std::string& fname ) const;
		void readFromFile( const std::string& fname );
#endif
		TrainingInfo    train( const DataSet&, const Params& );
		ConfusionMatrix classify( const DataSet& ) const;
		ClassVal        classify( const DataPoint& ) const;

		void     printDot( const std::string& name, const Params& params ) const;
		void     printInfo( std::ostream&, const std::string& msg=std::string() ) const;
		uint     maxDepth() const { return _maxDepth; }
		size_t   nbLeaves() const;

	private:
		size_t p_pruning( const DataSet& );
		bool   p_buildTree( const DataSet&, const Params& params );
		void p_check() const
		{
//			assert( _tClassIndexMap.size() > 0 );
			if( _tClassIndexMap.size() == 0 )
				throw std::runtime_error( "program error, tree has no Class to Index map assigned" );
		}

};


//---------------------------------------------------------------------
#ifdef GRAPH_SERIALIZATION
} // namespace dtcpp
namespace boost {
namespace serialization {

    template<class Archive>
    void serialize( Archive& ar, dtcpp::NodeT& n, unsigned /*int version*/ )
    {
        ar & n._nodeId;
//        ar & n._type;
    }

} // namespace serialization
} // namespace boost
namespace dtcpp {
//---------------------------------------------------------------------
/// Save tree to file
/// \todo 20210506: As of today, this does not build, need to investigate
void
TrainingTree::saveToFile( const std::string& fname ) const
{
	std::ofstream f( fname );
	if( !f.is_open() )
		throw std::runtime_error( "unable to open file " + fname + " for saving tree" );
	boost::archive::text_oarchive oa( f );
    oa << _graph;
}
//---------------------------------------------------------------------
void
TrainingTree::readFromFile( const std::string& fname )
{
	std::ifstream f( fname );
	if( !f.is_open() )
		throw std::runtime_error( "unable to open file: " + fname + " for reading tree" );
	boost::archive::text_iarchive ia( f );
    ia >> _graph;
}
#endif // GRAPH_SERIALIZATION
//---------------------------------------------------------------------
/// Iterates on all nodes and counts the one that are not root, nor "decision" nodes
inline
size_t
TrainingTree::nbLeaves() const
{
	size_t c = 0;
	for(
		auto pit = boost::vertices( _graph );
		pit.first != pit.second;
		pit.first++
	)
	{
		auto type = _graph[*pit.first]._type;
		assert( type != NT_undef );
		if( type != NT_Root && type != NT_Decision )
			c++;
	}
	return c;
}


// % % % % % % % % % % % % % %
namespace priv {
// % % % % % % % % % % % % % %

//---------------------------------------------------------------------
/// Recursive function used to print the Dot file, prints the current node
inline
void
printDotNodeChilds( std::ostream& f, vertexT_t vert, const GraphT& graph )
{
	START;
//	COUT << "nb out edges=" << boost::out_degree( v, graph ) << "\n";
//	std::cout.precision(4);
	f.precision(3);
	for(
		auto pit=boost::out_edges(vert, graph);
		pit.first != pit.second;
		pit.first++
	)
	{
		auto target = boost::target( *pit.first, graph );
		assert( graph[target]._type != NT_undef );

		f << graph[target]._nodeId
			<< " [label=\"n" << graph[target]._nodeId << ' ';

		if( graph[target]._type == NT_Decision )
			f << "attr=" << graph[target]._attrIndex
				<< " thres=" << graph[target]._threshold;
		else
			f << "C" << graph[target]._nClass
				<< ' ' << getString( graph[target]._type )
				<< "\\nGI=" << graph[target]._giniImpurity
				<< " A=" << graph[target]._nAmbig;

		f << "\\n#pts=" << graph[target].v_Idx.size() << "\"";
		switch( graph[target]._type )
		{
			case NT_Decision: f << ",color=green"; break;
			default:          f << ",color=red"; break;
//			default: assert(0);
		}
		f << "];\n" << graph[vert]._nodeId << "->" << graph[target]._nodeId  << ";\n";
		printDotNodeChilds( f, target, graph );
	}
}
// % % % % % % % % % % % % % %
} // namespace priv
// % % % % % % % % % % % % % %

//---------------------------------------------------------------------
/// Print a DOT file of the tree by calling the recursive function \ref printDotNodeChilds()
inline
void
TrainingTree::printDot( const std::string& name, const Params& params ) const
{
	auto fname = "tree"
		+ ( params.foldIndex==-1 ? "" : "_f" + std::to_string(params.foldIndex) )
		+ "_" + name;

	*params.outputHtml << "<h4>" << name << " tree</h4>\n<img src='" << fname << ".png'>\n";

	auto f = priv::openOutputFile( fname, priv::FT_DOT );
	f << "# file: " << _dataFileName << "\n\n"
		<< "digraph g {\nnode [shape=\"box\"];\n"
		<< "title [label=\"data file: " << _dataFileName
		<< "\\n" << nbLeaves()
		<< " leaves\",shape=\"note\",labelloc=\"c\"];\n"
		<< _graph[_initialVertex]._nodeId
		<< " [label=\"n" << _graph[_initialVertex]._nodeId
		<< " attr="     << _graph[_initialVertex]._attrIndex
		<< " thres="    << _graph[_initialVertex]._threshold
		<< "\\n#"      << _graph[_initialVertex].v_Idx.size()
		<< "\",color = blue];\n";

	f << "legend [label=\""
		<< "MGI: Min Gini Impurity\\n"
		<< "SC: Single Class\\n"
		<< "MD: Max Depth\\n"
		<< "STS: Split Too Small\\n"
		<< "MP: Merged by pruning"
		<< "\",shape=\"note\",labelloc=\"l\"];\n";

	priv::printDotNodeChilds( f, _initialVertex, _graph );
	f << "}\n";
}

//---------------------------------------------------------------------
/// Print basic information on the tree
//template<typename T>
void
TrainingTree::printInfo( std::ostream& f, const std::string& msg ) const
{
	START;
	f << "Tree info: "
		<< msg
		<< "\n -nb nodes=" << boost::num_vertices( _graph )
		<< "\n -nb edges=" << boost::num_edges( _graph )
		<< "\n -max depth=" << maxDepth()
		<< "\n -nb of leaves=" << nbLeaves()
		<< '\n';
}

//---------------------------------------------------------------------
/// Computes the class counting and returns it along with the number of relevant
/// points (that is, without the classless points)
/**
- See related getGiniImpurity()
*/
std::pair<ClassCounter,size_t>
getNodeClassCount(
	const std::vector<uint>& v_dpidx, ///< datapoint indexes to consider
	const DataSet&           data     ///< dataset
)
{
	ClassCounter m;
	size_t nbClassLess = 0;
	for( auto idx: v_dpidx )
	{
		const auto& dp = data.getDataPoint( idx );
		if( dp.isClassLess() )
			nbClassLess++;
		else
			m[ dp.classVal() ]++;
	}
	assert( nbClassLess < v_dpidx.size() );

	return std::make_pair(
		m,                              // the class counters
		v_dpidx.size() - nbClassLess    // the number of relevant points
	);
}
//---------------------------------------------------------------------
/// Computes the Gini impurity value from the class count
/**
Input arg: map of class counts and relevant number of points

- See related getNodeClassCount()
*/
double
getGiniImpurity(
	const std::pair<ClassCounter,size_t>& pmap
)
{
	const auto& classVotes  = pmap.first;
	const auto& nbpts = pmap.second;
	assert( classVotes.size() > 0 );
	assert( nbpts > 0 );

	double giniCoeff = 1.;
	for( auto elem: classVotes )
	{
		auto v = 1. * elem.second / nbpts;
		giniCoeff -= v*v;
	}
	COUT << "global Gini Coeff=" << giniCoeff << '\n';
	assert( giniCoeff >= 0. );                        // has to be !!!
	return giniCoeff;
}


//---------------------------------------------------------------------
/// Utility function, sort vector and removes values whose difference is small
/**
This compares all the values and removes those which are "too close".

Say we have the values: <code>4 - 5 - 6 - 6.1 - 7 - 8</code> <br>
We want to remove the value "6.1"

First we compute the range: highest - lowest.
Here, \f$ range = 8 - 4 = 4 \f$ <br>
We check the differences between two consecutive values: <br>
\f$ d = \left| v_i - v_{i+1} \right| \f$ <br>
If \f$ d < coeff * range \f$, then it will be considered as "too close".
*/
size_t
removeDuplicates( std::vector<float>& vec, const Params& params )
{
	auto mm = std::minmax_element( std::begin(vec), std::end(vec) )	;
	auto k = (*mm.second - *mm.first) * params.removalCoeff;

	std::sort( vec.begin(), vec.end() );

// remove all values that are equal
	auto it_end = std::unique(
		std::begin(vec),
		std::end(vec),
		[k]                        // lambda
		( float v1, float v2 )
		{
			if( std::fabs(v1-v2) < k )
				return true;
			return false;
		}
	);
	size_t nb_removal = vec.end() - it_end;
	vec.erase( it_end, vec.end() );
	return nb_removal;
}

//---------------------------------------------------------------------
/// Holds all the data relative to an attribute to be able to select it, see computeBestThreshold()
struct AttributeData
{
	uint         _atIndex = 0u;         ///< Absolute attribute index
	float        _gain  = 0.f;          ///< Information gain, will be used to select which attribute we use
	ThresholdVal _threshold;            ///< Threshold value, will be set by training and used to classify
	size_t       _nbPtsLessThan = 0u;   ///< Nb of points that are less than the threshold
	bool         _unable = false;       ///< will be set to \c true if unable to find a good threshold

	AttributeData() : _unable(true)
	{}

	AttributeData( uint atIdx, float ig, ThresholdVal tval, uint nbpLT ) :
		_atIndex(atIdx),
		_gain(ig),
		_threshold(tval),
		_nbPtsLessThan(nbpLT)
	{}

	friend std::ostream&operator << ( std::ostream& f, const AttributeData& ad )
	{
		f << "AttributeData: index=" << ad._atIndex
			<< " gain=" << ad._gain
			<< " thres=" << ad._threshold
			<< " nbPointsLessThan=" << ad._nbPtsLessThan
			<< ' ';
		return f;
	}
};

//---------------------------------------------------------------------
#ifndef DTCPP_NEED_FOR_SPEED
/// Generates for each node and each attribute a data/plot file to show how classes are distributed,
/// depending on the threshold values
void
generateClassHistoPerTVal(
	uint                     nodeId,      ///< node Id (only needed to plot data)
	uint                     atIdx,       ///< current attribute index
	std::vector<float>&      v_thresVal,  ///< threshold values for that attribute
	const DataSet&           data,        ///< dataset
	const std::vector<uint>& v_dpidx      ///< indexes of considered points in dataset
)
{
	START;
	char sep = ' ';

	std::ostringstream oss;
	oss << "thresClassHisto_n" << nodeId << "_at" << atIdx;
	auto fdata = priv::openOutputFile( oss.str(), priv::FT_DAT, data._fname );

	fdata << "# generated from function " << __FUNCTION__
		<< "()\n\n# class content for node " << nodeId << ", attribute " << atIdx
		<< "\n#  - nb of threshold values=" << v_thresVal.size()
		<< "\n#  - nb of points=" << v_dpidx.size()
		<< '\n';

	assert( v_thresVal.size() );
//	if( v_thresVal.size() < 2 )
//		fdata << "# (empty data)\n";

	fdata << "\n# Columns:\n# thres_index binLow binHigh";
	for( size_t c=0; c<data.nbClasses(); c++ )
		fdata << " C" << c;
	fdata << "\n\n";

	for( size_t tIdx=0; tIdx<v_thresVal.size()+1; tIdx++ )
	{
		std::map<uint,size_t> ccount;                            // a map to count the number of points of each class in each bin

		for( size_t i=0; i<v_dpidx.size(); i++ )
		{
			const auto& dp = data.getDataPoint(i);
			const auto& atVal = dp.attribVal(atIdx);
			if( !dp.isClassLess() )
			{
				const auto& classIdx = data.getIndexFromClass( dp.classVal() );

				if( tIdx == 0 )                              // if attribute value is less than first threshold value
				{
					if( atVal < v_thresVal.front() )
						ccount[ classIdx ]++;
				}
				else
				{
					if( tIdx == v_thresVal.size() )          // if attribute value is higher than last threshold value
					{
						if( atVal >= v_thresVal.back() )
							ccount[ classIdx ]++;
					}
					else                                     // if attribute value is between threshold values
					{
						if( atVal >= v_thresVal[tIdx] && atVal < v_thresVal[tIdx+1] )
							ccount[ classIdx ]++;
					}
				}
			}
		}

		fdata << tIdx << sep;
		if( tIdx == 0 )
			fdata << "-inf " << v_thresVal.front();
		else
			if( tIdx == v_thresVal.size() )
				fdata << v_thresVal.back() << " +inf";
			else
				fdata << v_thresVal[tIdx] << sep << v_thresVal[tIdx+1];

		for( uint i=0; i<(uint)data.nbClasses(); i++ )
			fdata << sep << ccount[i];
		fdata << '\n';
	}
	fdata << "\n# (EOF)\n";

	auto fplot = priv::openOutputFile( oss.str(), priv::FT_PLT, data._fname );
	auto imwidth = std::min( (size_t)DTCPP_PLOT_MAX_WIDTH, 300 + v_thresVal.size()*12 );
	fplot << "\nset terminal pngcairo size " << imwidth << ",600"
		<< "\nset output '" << oss.str() << ".png'"
//		<< "\nset label 'file: " << data._fname << "' at screen 0.01, screen .98 noenhanced"
		<< "\nset style data histogram"
		<< "\nset style histogram rowstacked"
		<< "\nset style fill solid border -1"
		<< "\nset boxwidth 0.75"
		<< "\nset grid"
//		<< "\nset title 'Node "<< nodeId << ", Attribute " << atIdx << " (" << v_dpidx.size() << " pts)'"
		<< "\nset xlabel '" << v_thresVal.size() << " threshold values'";

	fplot << "\nplot '" << oss.str() << ".dat' using 4:xtic(1) ti '";


	const auto& ibm  = data.getIndexBimap();
	const auto& sibm = data.getStringIndexBimap();

	if( !sibm.size() )            // if we don't have string classes
		fplot << "class " << ibm.right.at(0) << "'";
	else
		fplot << "0:" << sibm.right.at(0) << "'";

	for( uint i=0; i<(uint)data.nbClasses()-1; i++ )
	{
		fplot << ", '' using " << 5+i << " ti '";
		if( !sibm.size() )                     // if no strings, just print the index
			fplot << "class " << ibm.right.at(i+1);
		else
			fplot << i+1 << ":" << sibm.right.at(i+1);
		fplot << "'";
	}
	fplot << '\n';
}
#endif

//---------------------------------------------------------------------
/// Computes for each of the given thresholds values (\c v_thresVal) all the
/// IG values and returns the best one.
/**
This function also produces a data file named \c out/thres_nX_atY.dat
(with \c X the node ID and Y the attribute index).
This file will hold for each threshold value the number of points lower and higher
than that value, and the associated IG.
*/
AttributeData
SearchBestIG(
	uint                     nodeId,      ///< node Id (only needed to plot data)
	uint                     atIdx,       ///< current attribute index
	double                   giniCoeff,   ///< global Gini coeff
	std::vector<float>&      v_thresVal,  ///< threshold values
	const DataSet&           data,        ///< dataset
	const std::vector<uint>& v_dpidx,     ///< indexes of considered points in dataset
	std::ostream&            fhtml        ///< html page, opened in caller function
)
{
	START;
	std::ostringstream oss;
	oss << "thres_n" << nodeId << "_at" << atIdx;
	auto fdata = priv::openOutputFile( oss.str(), priv::FT_DAT, data._fname );
	char sep = ' ';
	fdata << "# thres_index thres_value nbPtsLower nbPtsHigher\n\n";

	fhtml << "<td>\n <img src='" << oss.str()
		<< ".png'><br>\n <img src='thresClassHisto_n" << nodeId << "_at" << atIdx
		<< ".png'>\n</td>\n";

	auto pwidth = std::min( (size_t)DTCPP_PLOT_MAX_WIDTH, 300+v_thresVal.size()*12 );
	auto fplot = priv::openOutputFile( oss.str(), priv::FT_PLT, data._fname );
	fplot << "\nset terminal pngcairo size " << pwidth << ",500\n"
		<< "\nset datafile separator ' '"
		<< "\nset grid"
		<< "\nset xlabel 'Threshold index'"
		<< "\nset xtics 1"
		<< "\nset yrange [0:1]"
		<< "\nset y2range [*:*]"
		<< "\nset y2tics"
		<< "\nset style data linespoints"
		<< "\nset output '" << oss.str() << ".png'"
//		<< "\nset title 'Attribute " << atIdx << " node " << nodeId << " (" << v_dpidx.size() << " pts)'"
		<< "\nset xtics 1"
		<< '\n';
	if( v_thresVal.size() > 9 )
		fplot << "set xtics 2\n";
	if( v_thresVal.size() > 24 )
		fplot << "set xtics 5\n";

	fplot //<< "set title 'Attribute " << atIdx << "'\n"
		<< "set xlabel '" << v_thresVal.size() << " threshold values'\n"
		<< "plot '" << oss.str() << ".dat' using 1:(1.-abs($3-$4)/($3+$4)) lw 2 ti 'Pts balance',"
		<< " '' using 1:5 lw 2 axes x1y2 ti 'IG'\n";

#ifndef DTCPP_NEED_FOR_SPEED
	generateClassHistoPerTVal( nodeId, atIdx, v_thresVal, data, v_dpidx );
#endif

	std::vector<float> deltaGini( v_thresVal.size() );   // one value per threshold
	std::vector<uint> nb_LT( v_thresVal.size(), 0u );    // will hold the nb of points lying below the threshold
	for( size_t i=0; i<v_thresVal.size(); i++ )          // for each threshold value
	{
//		COUT << "thres " << i << "=" << v_thresVal[i] << '\n';
		ClassCounter m_LT, m_HT;

		size_t nb_HT = 0;
		for( auto ptIdx: v_dpidx )                         // for each data point
		{
			const auto& point = data.getDataPoint(ptIdx);
			if( !point.isClassLess() )
			{
				auto attribVal = point.attribVal( atIdx );
#ifdef HANDLE_MISSING_VALUES
				bool usePoint = true;
				if( point.valueIsMissing( atIdx ) )
				{
					switch( DataSet::s_MissingValueStrategy )
					{
						case En_MVS::disablePoint: usePoint=false; break;
						case En_MVS::setToMean: assert(0); ///\todoM we need to have access to the dataset stats
							//attribVal = MEAN_VALUE_OF ATTRIBUTE
						break;
						default: assert(0);
					}
				}
				if( usePoint )
#endif
				{
					if( attribVal < v_thresVal[i] )
					{
						m_LT[ point.classVal() ]++;
						nb_LT[i]++;
					}
					else
					{
						m_HT[ point.classVal() ]++;
						nb_HT++;
					}
				}
			}
		}

		auto g_LT = 1.;
		for( auto p: m_LT )  // for the values that are Lower Than the threshold
		{
			auto val = 1. * p.second / nb_LT[i];
			g_LT -= val*val;
		}

		auto g_HT = 1.;
		for( auto p: m_HT )  // for the values that are Higher Than the threshold
		{
			auto val = 1. * p.second / nb_HT;
			g_HT -= val*val;
		}
		deltaGini[i] = giniCoeff - (g_LT + g_HT) / 2.;

		fdata << i << sep << v_thresVal[i] << sep << nb_LT[i] << sep << nb_HT << sep << deltaGini[i] << '\n';
	}

// step 3 - find max value of the delta Gini
//	auto max_pos = std::max_element( std::begin( deltaGini ), std::end( deltaGini ) );
	auto max_pos = std::min_element( std::begin( deltaGini ), std::end( deltaGini ) );

	auto best_thres_idx = std::distance( std::begin( deltaGini ), max_pos );

	LOG( 3, "Best threshold for attribute=" <<  atIdx << " among " << v_thresVal.size() << " values is at pos " << best_thres_idx << "=" << v_thresVal.at( best_thres_idx ) );
	return AttributeData(
		atIdx,
		*max_pos,
		ThresholdVal(v_thresVal.at( best_thres_idx ) ),
		nb_LT.at( best_thres_idx )
	);
}

//---------------------------------------------------------------------
/// Helper function, builds the vector of threshold values using sorting of the attribute values
bool
thres_useSorting(
	uint                     atIdx,
	const std::vector<uint>& v_dpidx,
	const DataSet&           data,
	const Params&            params,    ///< run-time parameters
	std::vector<float>&      v_thresVal    ///< output vector
)
{
	std::vector<float> v_attribVal( v_dpidx.size() ); // pre-allocate vector size (faster than push_back)
	for( size_t i=0; i<v_dpidx.size(); i++ )
		v_attribVal[i] = data.getDataPoint( v_dpidx[i] ).attribVal( atIdx );

	auto nbRemoval = removeDuplicates( v_attribVal, params );
	LOG( 3, "Removal of " << nbRemoval << " attribute values over " << v_dpidx.size() << " points" );

	if( v_attribVal.size() < 2 )         // if only one value, is pointless
	{
		LOG( 3, "WARNING, unable to compute best threshold value for attribute " << atIdx << ", maybe check value of 'removalCoeff'" );
		return false;
	}

	v_thresVal.resize( v_attribVal.size()-1 );      // if 10 values, then only 9 thresholds
	for( uint i=0; i<v_thresVal.size(); i++ )
		v_thresVal[i] = ( v_attribVal.at(i) + v_attribVal.at(i+1) ) / 2.f; // threshold is mean value between the 2 attribute values
	return true;
}
//---------------------------------------------------------------------
/// Helper function, builds the vector of threshold values using histograms
bool
thres_useHistograms(
	uint                     atIdx,     ///< attribute index we want to process
	const std::vector<uint>& v_dpidx,   ///< datapoint indexes to consider
	const DataSet&           data,
	std::vector<float>&      v_thresVal    ///< output vector
)
{
	using PairAtvalClass = std::pair<float,ClassVal>;
	std::vector<PairAtvalClass> v_pac( v_dpidx.size() ); // pre-allocate vector size (faster than push_back)
	for( size_t i=0; i<v_dpidx.size(); i++ )
	{
		const auto& pt = data.getDataPoint( v_dpidx[i] );
		if( !pt.isClassLess() )
			v_pac[i] = std::make_pair( pt.attribVal( atIdx ), pt.classVal() );
	}

	auto pair_vb = getThresholds<float,ClassVal>( v_pac, 20 );
	v_thresVal = std::move(pair_vb.first);
	if( pair_vb.second == false )
	{
		LOG( 3, "WARNING, unable to fetch threshold value for attribute " << atIdx );
		return false;
	}
	return true;
}

//---------------------------------------------------------------------
/// Compute best threshold for attribute \c atIdx, using the Gini Impurity, for the subset of data given by \c v_dpidx.
/**
\return an object of type AttributeData

Details:
- Uses the Gini impurity coeff: https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity
- for details, see
 - https://en.wikipedia.org/wiki/Information_gain_in_decision_trees
 - https://towardsdatascience.com/under-the-hood-decision-tree-454f8581684e

\todoM problem: for a given attribute here, we might have (after processing the histogram of attribute values) all the points having same class.
Thus, unable to find a threshold. How do we manage that
*/
//template<typename T>
AttributeData
computeBestThreshold(
	uint                     atIdx,     ///< attribute index we want to process
	const std::vector<uint>& v_dpidx,   ///< datapoint indexes to consider
	const DataSet&           data,      ///< dataset
	double                   giniCoeff, ///< Global Gini coeff for all the points
	const Params&            params,    ///< run-time parameters
	uint                     nodeId,
	std::ostream&            fhtml
)
{
	START;
	LOG( 3, "Searching best threshold for node " << nodeId << ", attrib=" << atIdx << " with " << v_dpidx.size() << " datapts");

	std::vector<float> v_thresVal;
	if( params.useSortToFindThresholds )
	{
		if( false == thres_useSorting( atIdx, v_dpidx, data, params, v_thresVal ) )
			return AttributeData();
	}
	else
	{
		if( false == thres_useHistograms( atIdx, v_dpidx, data, v_thresVal ) )
			return AttributeData();
	}

	LOG( 3, "found " << v_thresVal.size() << " thresholds, searching best one" );

// step 2: compute IG for each threshold value
	auto big = SearchBestIG( nodeId, atIdx, giniCoeff, v_thresVal, data, v_dpidx, fhtml );

	auto n1 = big._nbPtsLessThan;
	auto n2 = v_dpidx.size() - n1;
	if( n1 < params.minNbPoints || n2 < params.minNbPoints )
	{
		LOG( 1, "not enough points if splitting on best threshold for attribute " << big._atIndex << ": n1=" << n1 << " n2=" << n2 );
		return AttributeData();
	}
	return big;
}
//---------------------------------------------------------------------
/// Dummy version, needed only for tests. See other one.
AttributeData
computeBestThreshold(
	uint                     atIdx,     ///< attribute index we want to process
	const std::vector<uint>& v_dpidx,   ///< datapoint indexes to consider
	const DataSet&           data,      ///< dataset
	double                   giniCoeff, ///< Global Gini coeff for all the points
	const Params&            params     ///< run-time parameters
)
{
	std::ofstream f;
	return computeBestThreshold( atIdx, v_dpidx, data, giniCoeff, params, 0, f );
}
//---------------------------------------------------------------------
#if 0
/// Wrapper around a map holding a bool for each attribute index.
/// Used to check if an attribute has been already used or not.
/**
 * Benefit: has automatic initialization
*/
struct AttribMap
{
	private:
		std::map<uint,bool> _attribMap;
	public:
		explicit AttribMap( uint nbAttribs )
		{
			for( uint i=0; i<nbAttribs; i++ )
				_attribMap[i] = false;
		}
		const std::map<uint,bool>& getMap() const
		{
			return _attribMap;
		}
		std::map<uint,bool>& getMap()
		{
			return _attribMap;
		}
/// Set attribute \c idx as used, so we will not use it again
/// \todoL maybe add some checking here...
		void setAsUsed( uint idx )
		{
			_attribMap[idx] = true;
		}
		const std::map<uint,bool>::const_iterator begin() const
		{
			return std::begin( _attribMap );
		}
		const std::map<uint,bool>::const_iterator end() const
		{
			return std::end( _attribMap );
		}
/// Returns number of unused attributes
		uint nbUnusedAttribs() const
		{
			uint c=0;
			for( const auto& elem: _attribMap )
				if( elem.second == false )
					c++;
			return c;
		}
};
#endif
//---------------------------------------------------------------------
/// Finds the best attributes to use, considering the data points of the current node
/// and compute thresholds on that attribute so that the two classes are separated at best.
/**
\return object of type AttributeData, holding all the details

Two steps:
- first, find for each attribute the best IG of that attribute
- second, select the attribute that has the best one.
*/
//template<typename T>
AttributeData
findBestAttribute(
	const std::vector<uint>& vIdx,   ///< indexes of data points we need to consider
	const DataSet&           data,   ///< whole dataset
	const Params&            params, ///< parameters
	uint                     nodeId, ///< node Id, used to generate data and plot file for that node
	const ClassCounter&      ccount, ///< class count (only non-classless points)
	double                   giniImpurity,
	std::ostream&            fhtml
)
{
	START;
//	assert( atMap.nbUnusedAttribs() != 0 );

	LOG( 2, "Searching all thresholds among " << data.nbAttribs() << " attributes" );

	fhtml << "<tr><th></th>\n";
	for( uint i=0; i<data.nbAttribs(); i++ )
		fhtml << "<th>Attribute " << i << "</th>\n";
	fhtml << "</tr>\n<tr><th>Node " << nodeId << "<br>" << vIdx.size() << " pts</th>\n";

// step 1 - compute best IG/threshold for each attribute, only for the considered points
	std::vector<AttributeData> v_IG;

// for each attribute, we compute the best threshold
	for( size_t atIdx=0; atIdx<data.nbAttribs(); atIdx++ )  // iterate on all the attributes
	{
		auto best = computeBestThreshold( atIdx, vIdx, data, giniImpurity, params, nodeId, fhtml );
		if( best._unable )        // this means we couldn't find a threshold, so
		{                         // we forget this one and we switch to the next attribute
			LOG( 2, "unable to compute thresholds for attrib " << atIdx );
		}
		else
			v_IG.push_back( best );
	}
	fhtml << "</tr>\n";

	if( v_IG.empty() )
		return AttributeData(); // unable

// step 3 - get the one with max gain value
	LOG( 2, "search for best attribute among " << v_IG.size() << " attributes" );
	auto it_mval = std::max_element(
		std::begin(v_IG),
		std::end(v_IG),
		[]                         // lambda
		( const AttributeData& p1, const AttributeData& p2 )
		{
			return p1._gain < p2._gain;
		}
	);

	LOG( 2, "highest IG with attribute " << it_mval->_atIndex << ", GI=" << it_mval->_gain );

	return *it_mval;
}
//---------------------------------------------------------------------

// % % % % % % % % % % % % % %
namespace priv {
// % % % % % % % % % % % % % %

//---------------------------------------------------------------------
/// Helper function for splitNode()
auto
addChildPair( vertexT_t v, GraphT& graph, size_t nbElems )
{
	auto v1 = boost::add_vertex(graph);
	auto v2 = boost::add_vertex(graph);

	graph[v1]._depth = graph[v]._depth+1;
	graph[v2]._depth = graph[v]._depth+1;

	auto et = boost::add_edge( v, v1, graph );
	auto ef = boost::add_edge( v, v2, graph );
	graph[et.first].edgeSide = true;
	graph[ef.first].edgeSide = false;

//	COUT << "two nodes added, total nb=" << boost::num_vertices(graph) << "\n";

	graph[v1].v_Idx.reserve( nbElems );
	graph[v2].v_Idx.reserve( nbElems );
	COUT << "created nodes " << graph[v1]._nodeId << " and " << graph[v2]._nodeId << '\n';
	return std::make_pair(v1,v2);
}
//---------------------------------------------------------------------
/// Recursive helper function, used by TrainingTree::p_buildTree()
/**
Computes the threshold, splits the dataset and assigns the split to 2 sub nodes (that get created)
*/
////template<typename T>
void
splitNode(
	vertexT_t         v,         ///< current node id
	GraphT&           graph,     ///< graph
	const DataSet&    data,      ///< dataset
	const Params&     params,    ///< parameters
	uint&             maxDepth,  ///< maxDepth
	std::ostream&     fhtml      ///< html graph page
)
{
	START;

	const auto& vIdx = graph[v].v_Idx; // vector holding the indexes of the datapoints for this node
	LOG( 1, "Attempt to split node " << graph[v]._nodeId << " depth=" << graph[v]._depth << ", holding " << vIdx.size() << " points" );

// step 1.1 - check if there are different output classes in the given data points
// if not, then we are done

	const auto classCountInfo = getNodeClassCount( vIdx, data );
	const auto& classCount = classCountInfo.first;

	if( classCount.size() == 1 )         // single class here
	{
		LOG( 1, "node has single class, STOP" );
		graph[v]._nClass = classCount.begin()->first;          // no need to search for dominant class, there is only one !
		graph[v]._type = NT_Final_SC;
		graph[v]._nAmbig = 0.f;
		return;
	}

	graph[v]._giniImpurity = getGiniImpurity( classCountInfo );

	bool nodeIsLeave = false;
	if( graph[v]._depth > params.maxTreeDepth )
	{
		LOG( 1, "tree reached max depth (=" << params.maxTreeDepth << "), STOP" );
		graph[v]._type = NT_Final_MD;
		nodeIsLeave = true;
	}
	else
		if( graph[v]._giniImpurity < params.minGiniCoeffForSplitting )
		{
			LOG( 1, "dataset is (almost or completely) pure, gini coeff=" << graph[v]._giniImpurity << ", STOP" );
			graph[v]._type = NT_Final_GI_Small;
			nodeIsLeave = true;
		}

	if( nodeIsLeave )
	{
		auto fdc = priv1::findDominantClass( classCount );
		graph[v]._nClass = fdc.dominantClass;
		graph[v]._nAmbig = fdc.ambig;
		return;
	}

	// step 2 - find the best attribute to use to split the data, considering the data points of the current node
	auto bestAttrib = findBestAttribute( vIdx, data, params, graph[v]._nodeId, classCount, graph[v]._giniImpurity, fhtml );
	LOG( 1, "best attrib: " << bestAttrib );

	if( bestAttrib._unable )
	{
		LOG( 1, "unable to find good attribute" );
		graph[v]._type = NT_Final_SplitTooSmall;
		auto fdc = priv1::findDominantClass( classCount );
		graph[v]._nClass = fdc.dominantClass;
		graph[v]._nAmbig = fdc.ambig;
		return;
	}
//
// !!! from here, a split will occur !!!
//
	graph[v]._attrIndex = bestAttrib._atIndex;
	graph[v]._threshold = bestAttrib._threshold.get();
	graph[v]._giniImpurity = -1.f;
	if( graph[v]._type != NT_Root )   // so the root... stays the root !
		graph[v]._type = NT_Decision;

// step 3 - different classes here: we create two child nodes and split the dataset
	auto v1v2 = addChildPair( v, graph, vIdx.size() );
	auto v1 = v1v2.first;
	auto v2 = v1v2.second;
	maxDepth = std::max( maxDepth, graph[v1]._depth );

	for( auto idx: vIdx )           // separate the data points into two sets
	{
		auto attrVal = data.getDataPoint( idx ).attribVal( bestAttrib._atIndex );
		if( attrVal < bestAttrib._threshold.get() )
			graph[v1].v_Idx.push_back( idx );
		else
			graph[v2].v_Idx.push_back( idx );
	}
	LOG( 1, "after node split: v1: "<< graph[v1].v_Idx.size() << " points, v2: "<< graph[v2].v_Idx.size() << " points" );

	if( graph[v1].v_Idx.size() )
		splitNode( v1, graph, data, params, maxDepth, fhtml );

	if( graph[v2].v_Idx.size() )
		splitNode( v2, graph, data, params, maxDepth, fhtml );
}

//---------------------------------------------------------------------
// % % % % % % % % % % % % % %
} // namespace priv
// % % % % % % % % % % % % % %

//---------------------------------------------------------------------
/// Pruning of the graph: removal of child leaves pair that hold the same class
/**
\return The number of removal operations (\b not the number of removed nodes!)

Algorithm:
\verbatim
DO
	iterate through the vertices, until we have a removal:
		IF vertex it is a leave:
		THEN
			go up one step and check other child
			IF other child is a leave AND has same class
			THEN
				Merge the two vertices:
					tag parent as Leave
					remove the two childs
				removal = true
WHILE( no more removals )
\endverbatim

\note Could have tried something else:
check each node one by one and find if there is another node of same depth AND same class
that has the same parent.

\todoM integrate this in the main training function, so for end-user it gets automatically done.
*/
size_t
TrainingTree::p_pruning( const DataSet& data )
{
	START;

	LOG( 1, "start pruning, nb nodes=" + std::to_string( boost::num_vertices( _graph ) ) );

	size_t iter = 0;
	size_t nbRemoval = 0;
	bool removalHappened = false;
	do{
		COUT << "iter=" << iter++ << " nb vertices=" << boost::num_vertices( _graph ) << std::endl;
		removalHappened = false;
		std::set<uint> nodeSet;

		for(
			auto pit = boost::vertices( _graph );                // iterate on all the vertices
			pit.first != pit.second && !removalHappened;         // but stop if a removal happened
			pit.first++
		)
		{
			auto v1    = *pit.first;
			auto& node1 = _graph[v1];  // not const because in case of merging, the indexes vector will be added with the one from the other node
//			COUT << "current node:" << node1._nodeId << " class=" << node1._class << " depth="<< node1._depth << '\n';
			nodeSet.insert( node1._nodeId );
			if( node1.isLeave() && boost::num_vertices( _graph ) != 1)    // we only care about the leaves (and quit if only 1 node left)
			{
				assert( boost::in_degree( v1, _graph )  == 1 );
				auto pe_in = boost::in_edges( v1, _graph );       // get the ingoing edges (only 1 actually)
				auto v0 = boost::source( *pe_in.first, _graph );  // get source vertex
				assert( boost::out_degree( v0, _graph ) == 2 );

				auto pedges = boost::out_edges( v0, _graph );     // get the out-edges
				auto eit1 = pedges.first++;
				auto eit2 = pedges.first;

				edge_t other = *eit1;                         // if the first edge is
				if( other == *pe_in.first )                   // the one used to get here,
					other = *eit2;                            // then swap

				auto v2 = boost::target( other, _graph );     // other child
				const auto& node2 = _graph[v2];
				if( nodeSet.find( node2._nodeId ) == nodeSet.end() )  // if not already parsed
				{
					nodeSet.insert( node2._nodeId );                  // then, add it to the set of nodes already parsed
					if( node2.isLeave() )                             // if node is a leave of the tree
						if( node1._nClass == node2._nClass )            // and is same class !
						{
							_graph[v0]._nClass = node1._nClass;  // change status of source node
							if( _graph[v0]._type != NT_Root )
							{
								_graph[v0]._type = NT_Merged;

								auto n1size = node1.v_Idx.size();
								node1.v_Idx.resize( n1size + node2.v_Idx.size() );
								std::copy( node2.v_Idx.begin(), node2.v_Idx.end(), node1.v_Idx.begin()+n1size );

								auto pm = getNodeClassCount( node1.v_Idx, data );
								_graph[v0]._giniImpurity = getGiniImpurity( pm );
								_graph[v0]._nAmbig       = priv1::findDominantClass( pm.first ).ambig;
							}
							boost::clear_vertex(  v1, _graph );
							boost::clear_vertex(  v2, _graph );
							boost::remove_vertex( v1, _graph );
							boost::remove_vertex( v2, _graph );
							nbRemoval++;
							removalHappened = true;
							break;
						}
				}
			}
		}
	}
	while( removalHappened );
	return nbRemoval;
}
//---------------------------------------------------------------------
/// Train tree using data.
//template<typename T>
TrainingInfo
TrainingTree::train( const DataSet& data, const Params& params )
{
	TrainingInfo info;
	clear();
	if( p_buildTree( data, params ))
	{
		*params.outputHtml << "<h3>B2 - Generated Tree</h3>\n";
		info.trainingSuccess = true;
		if( params.generateDotFiles )
			printDot( "initial", params );

		info.nbRemovals = p_pruning( data );
		if( params.generateDotFiles )
			printDot( "pruned", params );
	}
	else
		*params.outputHtml << "<h3>Tree build failure !!</h3>\n";

	return info;
}
//---------------------------------------------------------------------
/// Train tree using data.
//template<typename T>
bool
TrainingTree::p_buildTree( const DataSet& data, const Params& params )
{
	START;
	LOG( 0, "Start training" );
	p_check();

	_dataFileName = data._fname;

	auto nbAttribs = data.nbAttribs();
	if( !nbAttribs )
		throw std::runtime_error( "no attributes!" );
	if( data.size()<2 )
		throw std::runtime_error( "no enough data points!" );

	std::vector<uint> v_idx;
	v_idx.reserve( data.size() );
#ifdef HANDLE_OUTLIERS
	if( data.nbOutliers() )                     // if outliers there,
	{                                           // then we put in the
		for( size_t i=0; i<data.size(); i++ )   // set of indexes only
			if( !data.pointIsOutlier(i) )       // the points that are not outliers
				v_idx.push_back( i );
	}
	else
#endif
	{
		v_idx.resize( data.size() );  // create vector holding indexes of all the data points
		std::iota( v_idx.begin(), v_idx.end(), 0 );
	}

//	auto fhtml = priv::openOutputFile( "training", priv::FT_HTML, data._fname );
	auto& fhtml = *params.outputHtml;
	fhtml << "<h2>B - Tree build </h2>\n<h3>B1 - Point balance and IG vs. threshold value for each node</h2>\n<table>\n";

	_graph[_initialVertex].v_Idx = v_idx;
	COUT << "INITIAL ID=" << _graph[_initialVertex]._nodeId << '\n';
	priv::splitNode( _initialVertex, _graph, data, params, _maxDepth, fhtml ); // Call the "split" function (recursive)

	fhtml << "</table>\n";

	if( nbLeaves() < 2 )  // has to be at least 2 leaves
	{
		std::cerr << "fail, unable to build tree, only " << nbLeaves() << " leaves\n";
		return false;
	}
	LOG( 0, "Training done" );
	return true;
}

//---------------------------------------------------------------------
/// Returns class of data point as classified by tree
//template<typename T>
ClassVal
TrainingTree::classify( const DataPoint& point ) const
{
	START;
	ClassVal retval{-1};
	if( !nbLeaves() )
	{
		std::cerr << "Error, unable to classify point, tree has no leaves!\n";
		return retval;
	}

#ifdef HANDLE_MISSING_VALUES
	if( point.nbMissingValues() )
	{
		std::cerr << "Error, unable to classify point, has missing attribute values\n";
		return retval;
	}
#endif

	vertexT_t v = _initialVertex;   // initialize to first node
	bool done = false;
	do
	{
		assert( _graph[v]._type != NT_undef );
		if( _graph[v]._type != NT_Root && _graph[v]._type != NT_Decision ) // then, we are done !
		{
			done = true;
			retval = _graph[v]._nClass;
		}
		else
		{
			auto attrIndex = _graph[v]._attrIndex;  // get attrib index that this node handles
			auto atValue   = point.attribVal( attrIndex );  // get data point value for this attribute

			assert( boost::out_degree( v, _graph ) == 2 );

			auto edges = boost::out_edges( v, _graph );    // get the two output edges of the node
			auto et = edges.first++;
			auto ef = edges.first;
			if( _graph[*ef].edgeSide )
				std::swap( et, ef );

//			COUT << "node thres=" << _graph[v]._threshold << std::endl;
			if( atValue < _graph[v]._threshold )  // depending on threshold, define the next node
				v = boost::target( *et, _graph );
			else
				v = boost::target( *ef, _graph );
		}
	}
	while( !done );
	return retval;
}

//---------------------------------------------------------------------
/// Classify \c dataset and returns performance score
ConfusionMatrix
TrainingTree::classify( const DataSet& dataset ) const
{
//	if( _nbClasses < 2 )  // if 0 or 1 class, then nothing to classify
//		throw std::runtime_error( "nothing to classify, dataset holds " + std::to_string(_nbClasses) + " classes" );
	START;
	p_check();

	ConfusionMatrix confmat( _tClassIndexMap );
	if( nbLeaves() > 1)
	{
		for( const auto& datapoint: dataset )
			if( !datapoint.isClassLess() )
			{
				auto cla1 = datapoint.classVal();
				auto cla2 = classify( datapoint );
				confmat.add( cla1, cla2 );
			}
	}
	else
		std::cerr << "Error, unable to classify dataset, tree has " << nbLeaves() << " leave!\n";
	return confmat;
}
//---------------------------------------------------------------------
/// Print the scores for all available performance criterions, for the given ConfusionMatrix
/**
Type \c T will be either \ref PerfScore_MC (for multiclass) or \ref PerfScore (for 2-class problems)
*/
template<typename T>
void
printScores( std::ostream& f, const ConfusionMatrix& cm )
{
	for( int pc=0; pc<static_cast<int>(T::SCORE_END); pc++ )
	{
		auto crit = static_cast<T>(pc);
		f << "   - Criterion: " << getString( crit ) << " => "
			<< cm.getScoreT<T>( crit ) << '\n';
	}
}
//---------------------------------------------------------------------
/// Print the scores for all available performance criterions, for all
/// the given ConfusionMatrix in \c vcm
/**
Type \c T will be either \ref PerfScore_MC (for multiclass) or \ref PerfScore (for 2-class problems)
*/
template<typename T>
void
printAllScores(
	std::ostream& f,
	const std::vector<ConfusionMatrix>& vcm
)
{
	assert( vcm.size()>1 );
	for( int pc=0; pc<static_cast<int>(T::SCORE_END); pc++ )
	{
		f << " * Criterion: " << getString( static_cast<T>(pc) ) << ":\n";
		for( size_t i=0; i<vcm.size(); i++ )
			f << "  - fold " << i+1 << ": "
				<< vcm[i].getScoreT<T>( static_cast<T>(pc) )
				<< '\n';
	}
}
//---------------------------------------------------------------------
template<typename T>
void
printBestCriterionFold(
	std::ostream&                       f,
	const std::vector<TrainingTree>&    vec_tree,
	const std::vector<ConfusionMatrix>& vec_cm_test,
	const DataSet&                      dataset
)
{
	std::set<size_t> bestSet;
	f << "*** Folding best performance ***\n";
	for( int ps=0; ps<static_cast<int>(T::SCORE_END); ps++ )
	{
		auto perfCrit = static_cast<T>(ps);
		auto best = findMaxPerformance( vec_cm_test, perfCrit );
		f << " * Criterion: " << getString( perfCrit ) << " => best: fold " << best+1 << '\n';

		if( bestSet.find( best ) == std::end( bestSet ) )
		{
			f << "  - Classifying whole data set with that tree:\n";
			auto cm_all = vec_tree[best].classify( dataset );
			printScores<T>( f, cm_all );
			bestSet.insert( best );
		}
	}
}

//---------------------------------------------------------------------
/// Finds among all the confusion matrix the one achieving highest performance
/// based on criterion \c T
template<typename T>
size_t
findMaxPerformance( const std::vector<ConfusionMatrix>& vcm, T crit )
{
	double maxp = std::numeric_limits<double>::min();
	size_t best = 0;
	for( size_t i=0; i<vcm.size(); i++ )
	{
		auto score = vcm[i].getScoreT<T>( crit );
		if( maxp < score )
		{
			maxp = score;
			best = i;
		}
	}
	return best;
}

} // namespace dtcpp
//---------------------------------------------------------------------
#endif // DTCPP_HG
